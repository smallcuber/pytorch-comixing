{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from model import CNN, ReshapedPreTrainedModel\n",
    "from loss import loss_coteaching\n",
    "from optuna.trial import TrialState\n",
    "import optuna\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from mixup import mixup_data\n",
    "from model import dict_models, load_pretrained_model_by_name\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from loader_CIFAR import CifarDataloader, CifarDataset, unpickle\n",
    "from loader_ANIMAL10N import Animal10N\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "\n",
    "# torch.autograd.set_detect_anomaly(True)\n",
    "# test the custom loaders for CIFAR\n",
    "name_dataset = 'cifar10'  # either cifar10 or animal10n\n",
    "id_task = 1  # Task 1 to 3, noise file created by TA\n",
    "data_path_animal = 'rawdata_ANIMAL10N'\n",
    "# data_path = 'rawdata_CIFAR10'\n",
    "data_path = \"C://Users//Wenda//Documents//Pytorch//rawdata_CIFAR10\"\n",
    "# path to the data file (don't forget to download the feature data and also put the noisy label file under this folder)\n",
    "\n",
    "num_iter_per_epoch = 100\n",
    "num_print_freq = 100\n",
    "num_epoch = 200\n",
    "num_batch_size = 128\n",
    "num_gradual = 10\n",
    "num_exponent = 1\n",
    "num_forget_rate = 0.1\n",
    "num_noise_rate = 0.2\n",
    "num_workers = 6\n",
    "num_classes = 10\n",
    "num_learning_rate = 0.001\n",
    "num_input_channel = 3\n",
    "\n",
    "# Adjust learning rate and betas for Adam Optimizer\n",
    "num_mixup_alpha = 0.1\n",
    "num_epoch_decay_start = 80\n",
    "mom1 = 0.9\n",
    "mom2 = 0.1\n",
    "alpha_plan = [num_learning_rate] * num_epoch\n",
    "beta1_plan = [mom1] * num_epoch\n",
    "for i in range(num_epoch_decay_start, num_epoch):\n",
    "    alpha_plan[i] = float(num_epoch - i) / (num_epoch - num_epoch_decay_start) * num_learning_rate\n",
    "    beta1_plan[i] = mom2\n",
    "\n",
    "rate_schedule = np.ones(num_epoch) * num_forget_rate\n",
    "rate_schedule[:num_gradual] = np.linspace(0, num_forget_rate ** num_exponent, num_gradual)\n",
    "\n",
    "json_noise_file_names = {\n",
    "    1: 'cifar10_noisy_labels_task1.json',\n",
    "    2: 'cifar10_noisy_labels_task2.json',\n",
    "    3: 'cifar10_noisy_labels_task3.json'\n",
    "}\n",
    "noise_file_name = json_noise_file_names[id_task]  # Change The number to switch tasks\n",
    "\n",
    "if name_dataset == 'cifar10':\n",
    "    loader = CifarDataloader(name_dataset, batch_size=128,\n",
    "                             num_workers=10,\n",
    "                             root_dir=data_path,\n",
    "                             noise_file='%s/%s' % (data_path, noise_file_name))\n",
    "    train_loader, noisy_labels, clean_labels = loader.run('train')\n",
    "    noise_or_not = np.transpose(noisy_labels) == np.transpose(clean_labels)\n",
    "    test_loader = loader.run('test')\n",
    "else:\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    dataset_train = Animal10N(split='train', transform=transform_train)\n",
    "    dataset_test = Animal10N(split='test', transform=transform_test)\n",
    "\n",
    "    train_loader = DataLoader(dataset_train, batch_size=num_batch_size, shuffle=True, num_workers=num_workers)\n",
    "    test_loader = DataLoader(dataset_test, batch_size=num_batch_size * 2, shuffle=False, num_workers=num_workers)\n",
    "    noise_or_not = None\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_full_name = f'{name_dataset}_{noise_file_name}'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "#\n",
    "# def imshow(axis, inp):\n",
    "#     \"\"\"Denormalize and show\"\"\"\n",
    "#     inp = inp.numpy().transpose((1, 2, 0))\n",
    "#     mean = np.array([0.485, 0.456, 0.406])\n",
    "#     std = np.array([0.229, 0.224, 0.225])\n",
    "#     inp = std * inp + mean\n",
    "#     axis.imshow(inp)\n",
    "# img, label, idx = next(iter(train_loader))\n",
    "# print(img.size(), label.size())\n",
    "# fig = plt.figure(1, figsize=(16, 4))\n",
    "# grid = ImageGrid(fig, 111, nrows_ncols=(1, 4), axes_pad=0.05)\n",
    "# for i in range(img.size()[0]):\n",
    "#     ax = grid[i]\n",
    "#     imshow(ax, img[i])\n",
    "#     break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = alpha_plan[epoch]\n",
    "        param_group['betas'] = (beta1_plan[epoch], 0.999)  # Only change beta1\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "# TODO: Complete migrating the Co-Teaching model\n",
    "def accuracy(logit, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    output = F.softmax(logit, dim=1)\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "\n",
    "def train(loader_train, epoch, model1, optimizer1, model2, optimizer2, criterion, _rate_schedule, _mixup_alpha,\n",
    "          _iter_per_epoch):\n",
    "    print(\"Training... %s\" % model_full_name)\n",
    "    pure_ratio_list = []\n",
    "    _pure_ratio_1_list = []\n",
    "    _pure_ratio_2_list = []\n",
    "    count_total_train1 = 0\n",
    "    count_total_correct1 = 0\n",
    "    count_total_train2 = 0\n",
    "    count_total_correct2 = 0\n",
    "    num_correct_1 = 0\n",
    "    num_correct_2 = 0\n",
    "    num_total = 0\n",
    "    model1.to(device)\n",
    "    model2.to(device)\n",
    "\n",
    "    for i, (images, labels, indexes) in enumerate(loader_train):\n",
    "        # ind = indexes.cpu().numpy().transpose()\n",
    "        ind = indexes.numpy().transpose()\n",
    "        if i > _iter_per_epoch > 0:\n",
    "            break\n",
    "\n",
    "        images = Variable(images).to(device)\n",
    "        labels = Variable(labels).to(device)\n",
    "        num_total = labels.size(0)\n",
    "\n",
    "        images, label_a, label_b, lam = mixup_data(images, labels, device, _mixup_alpha)\n",
    "\n",
    "        # Forward Backward Optimize\n",
    "        output1 = model1(images)\n",
    "        _, predicted1 = torch.max(output1.data, 1)\n",
    "        prec1, _ = accuracy(output1, labels, topk=(1, 5))\n",
    "        count_total_train1 += 1\n",
    "        count_total_correct1 += prec1\n",
    "\n",
    "        output2 = model2(images)\n",
    "        _, predicted2 = torch.max(output2.data, 1)\n",
    "        prec2, _ = accuracy(output2, labels, topk=(1, 5))\n",
    "        count_total_train2 += 1\n",
    "        count_total_correct2 += prec2\n",
    "\n",
    "        num_correct_1 += (lam * predicted1.eq(label_a.data).cpu().sum().float()\n",
    "                          + (1 - lam) * predicted1.eq(label_b.data).cpu().sum().float())\n",
    "        num_correct_2 += (lam * predicted2.eq(label_a.data).cpu().sum().float()\n",
    "                          + (1 - lam) * predicted2.eq(label_b.data).cpu().sum().float())\n",
    "        # num_correct_1 += (lam * predicted1.eq(label_a.data).cpu().sum().float()\n",
    "        #                   + (1 - lam) * predicted1.eq(label_b.data).cpu().sum().float())\n",
    "        # num_correct_2 += (lam * predicted2.eq(label_a.data).cpu().sum().float()\n",
    "        #                   + (1 - lam) * predicted2.eq(label_b.data).cpu().sum().float())\n",
    "        num_acc_1 = num_correct_1 / num_total\n",
    "        num_acc_2 = num_correct_2 / num_total\n",
    "\n",
    "        loss1, loss2, pure_ratio_1, pure_ratio_2 = loss_coteaching(criterion, output1, output2, labels, label_a,\n",
    "                                                                   label_b, _rate_schedule[epoch], ind, noise_or_not,\n",
    "                                                                   lam)\n",
    "\n",
    "        if pure_ratio_1 and pure_ratio_2 is not None:\n",
    "            _pure_ratio_1_list.append(100 * pure_ratio_1)\n",
    "            _pure_ratio_2_list.append(100 * pure_ratio_2)\n",
    "\n",
    "        optimizer1.zero_grad()\n",
    "        loss1.backward()\n",
    "        optimizer1.step()\n",
    "        optimizer2.zero_grad()\n",
    "        loss2.backward()\n",
    "        optimizer2.step()\n",
    "        if (i + 1) % num_print_freq == 0:\n",
    "            if pure_ratio_1 and pure_ratio_2 is not None:\n",
    "                str_calc_pure_ratio = 'Pure Ratio1: %.4f, Pure Ratio2 %.4f' % (\n",
    "                    np.sum(_pure_ratio_1_list) / len(_pure_ratio_1_list),\n",
    "                    np.sum(_pure_ratio_2_list) / len(_pure_ratio_2_list))\n",
    "            else:\n",
    "                str_calc_pure_ratio = 'Animal10N dataset without pure ratio'\n",
    "\n",
    "            print(\n",
    "                'Train Epoch [%d/%d], Iter [%d/%d] Training Accuracy1: %.4F, Training Accuracy2: %.4f, Loss1: %.4f, Loss2: %.4f, %s'\n",
    "                % (epoch + 1, num_epoch, i + 1, len(train_loader) // num_batch_size, num_acc_1, num_acc_2, loss1.item(),\n",
    "                   loss2.item(), str_calc_pure_ratio))\n",
    "\n",
    "\n",
    "    train_acc1 = float(count_total_correct1) / float(count_total_train1)\n",
    "    train_acc2 = float(count_total_correct2) / float(count_total_train2)\n",
    "    return train_acc1, train_acc2, _pure_ratio_1_list, _pure_ratio_2_list\n",
    "\n",
    "\n",
    "def evaluate(_test_loader, model1, model2, particial_test_rate=0):\n",
    "    print('Evaluating %s...' % model_full_name)\n",
    "    # model1 = model1.to(device)  # Change model to 'eval' mode.\n",
    "    # model2 = model2.to(device)\n",
    "    correct1 = 0\n",
    "    total1 = 0\n",
    "    print(\"Start evaluating model 1\")\n",
    "    for images, labels in _test_loader:\n",
    "        images = Variable(images).to(device)\n",
    "        labels = labels.to(device)\n",
    "        logits1 = model1(images)\n",
    "        outputs1 = F.softmax(logits1, dim=1)\n",
    "        _, pred1 = torch.max(outputs1.data, 1)\n",
    "        total1 += labels.size(0)\n",
    "        correct1 += (pred1 == labels).sum()\n",
    "\n",
    "    print(\"Start evaluating model 2\")\n",
    "    model2.eval()  # Change model to 'eval' mode\n",
    "    correct2 = 0\n",
    "    total2 = 0\n",
    "    for images, labels in _test_loader:\n",
    "        images = Variable(images).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        logits2 = model2(images)\n",
    "        outputs2 = F.softmax(logits2, dim=1)\n",
    "        _, pred2 = torch.max(outputs2.data, 1)\n",
    "        total2 += labels.size(0)\n",
    "        correct2 += (pred2 == labels).sum()\n",
    "\n",
    "    acc1 = 100 * float(correct1) / float(total1)\n",
    "    acc2 = 100 * float(correct2) / float(total2)\n",
    "    return acc1, acc2\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "\n",
    "def main_single_train():\n",
    "    # Train the model\n",
    "\n",
    "    # Data Loader (Input Pipeline)\n",
    "    print('loading dataset...')\n",
    "\n",
    "    # Define models\n",
    "    print('building model...')\n",
    "    cnn1 = CNN(input_channel=num_input_channel, n_outputs=num_classes)\n",
    "    # cnn1 = ReshapedPreTrainedModel(modelC, n_outputs=10, dropout_rate=0.25, freeze_weights=True)\n",
    "    cnn1.to(device)\n",
    "    # print(cnn1.parameters)\n",
    "    optimizer1 = torch.optim.Adam(cnn1.parameters(), lr=num_learning_rate)\n",
    "\n",
    "    cnn2 = CNN(input_channel=num_input_channel, n_outputs=num_classes)\n",
    "    # cnn2 = ReshapedPreTrainedModel(modelC, n_outputs=10, dropout_rate=0.25, freeze_weights=True)\n",
    "    cnn2.to(device)\n",
    "    # print(cnn2.parameters)\n",
    "    optimizer2 = torch.optim.Adam(cnn2.parameters(), lr=num_learning_rate)\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss(reduce=False)\n",
    "\n",
    "    # training\n",
    "    for epoch in range(1, num_epoch):\n",
    "        # train models\n",
    "        cnn1.train()\n",
    "        adjust_learning_rate(optimizer1, epoch)\n",
    "        cnn2.train()\n",
    "        adjust_learning_rate(optimizer2, epoch)\n",
    "        train_acc1, train_acc2, pure_ratio_1_list, pure_ratio_2_list = train(train_loader, epoch, cnn1, optimizer1,\n",
    "                                                                             cnn2, optimizer2, criterion, rate_schedule,\n",
    "                                                                             num_mixup_alpha, num_iter_per_epoch)\n",
    "        # evaluate models\n",
    "        test_acc1, test_acc2 = evaluate(test_loader, cnn1, cnn2)\n",
    "        # save results\n",
    "        if name_dataset == 'cifar10n':\n",
    "            mean_pure_ratio1 = sum(pure_ratio_1_list) / len(pure_ratio_1_list)\n",
    "            mean_pure_ratio2 = sum(pure_ratio_2_list) / len(pure_ratio_2_list)\n",
    "            str_ratio = 'Pure Ratio 1 %.4f %%, Pure Ratio 2 %.4f' % (mean_pure_ratio1, mean_pure_ratio2)\n",
    "        else:\n",
    "            str_ratio = 'animal10n without pure ratio.'\n",
    "        print('Epoch [%d/%d] Test Accuracy on the %s test images: Model1 %.4f %% Model2 %.4f %%, %s' % (\n",
    "            epoch + 1, num_epoch, len(test_loader.dataset), test_acc1, test_acc2, str_ratio))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "def train_trial(_model_select,\n",
    "                _optimizer_select,\n",
    "                _learning_rate_scheduler_select,\n",
    "                trial,\n",
    "                _forget_rate=0.1, _gradual=10, _num_epoch=200, _num_mixup_alpha=0.1, _iter_per_epoch=200,\n",
    "                _num_exponent=1, _learning_rate=0.02, _freq_evaluate=1, _freeze_weights=True):\n",
    "    _rate_schedule = np.ones(_num_epoch) * _forget_rate\n",
    "    _rate_schedule[:_gradual] = np.linspace(0, _forget_rate ** _num_exponent, _gradual)\n",
    "\n",
    "    print('Start trail...')\n",
    "    # Define models\n",
    "    print('building model...')\n",
    "    if _model_select != \"CNN\":\n",
    "        print(f'Loading pre-trained model: {_model_select}')\n",
    "        _model1 = load_pretrained_model_by_name(_model_select, is_pretrained=True)\n",
    "        _model2 = load_pretrained_model_by_name(_model_select, is_pretrained=True)\n",
    "\n",
    "\n",
    "        if _freeze_weights:\n",
    "            for param in _model1.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in _model2.parameters():\n",
    "                param.requires_grad = False\n",
    "        num_input = _model1.classifier.in_features\n",
    "        _model1.classifier = torch.nn.Linear(num_input, num_classes, bias=True).to(device)\n",
    "        num_input = _model2.classifier.in_features\n",
    "        _model2.classifier = torch.nn.Linear(num_input, num_classes, bias=True).to(device)\n",
    "        _model1.to(device)\n",
    "        _model2.to(device)\n",
    "        # _model1 = modify_pretrained_outputs(_model1.to(device), num_output=num_classes, freeze_parameters=_freeze_weights)\n",
    "        # _model1 = modify_pretrained_outputs(_model2.to(device), num_output=num_classes, freeze_parameters=_freeze_weights)\n",
    "\n",
    "    else:\n",
    "        _model1 = CNN(input_channel=num_input_channel, n_outputs=num_classes)\n",
    "        _model2 = CNN(input_channel=num_input_channel, n_outputs=num_classes)\n",
    "        _model1.to(device)\n",
    "        _model2.to(device)\n",
    "\n",
    "    if _optimizer_select == \"Adam\":\n",
    "        _optm1 = torch.optim.Adam(_model1.parameters(), lr=_learning_rate)\n",
    "        _optm2 = torch.optim.Adam(_model2.parameters(), lr=_learning_rate)\n",
    "    else:\n",
    "        _optm1 = torch.optim.SGD(_model1.parameters(), lr=_learning_rate)\n",
    "        _optm2 = torch.optim.SGD(_model2.parameters(), lr=_learning_rate)\n",
    "\n",
    "    if _learning_rate_scheduler_select == \"StepLR\":\n",
    "        scheduler1 = lr_scheduler.StepLR(_optm1, step_size=30, gamma=0.5)\n",
    "        scheduler2 = lr_scheduler.StepLR(_optm2, step_size=30, gamma=0.5)\n",
    "\n",
    "    _criterion_select = torch.nn.CrossEntropyLoss(reduce=False)\n",
    "    _mean_pure_ratio1 = 0\n",
    "    _mean_pure_ratio2 = 0\n",
    "    _epoch = 0\n",
    "    _train_acc1 = 0\n",
    "    _train_acc2 = 0\n",
    "    _test_acc1, _test_acc2 = 0, 0\n",
    "\n",
    "    print(f\"Current model: {_model_select}, current optimizer: {_optimizer_select}, criterion: {_criterion_select}, lr schedule: {_learning_rate_scheduler_select}, forget rate: {_forget_rate}, gradual rate: {_gradual}, mixup alpha: {_num_mixup_alpha}\")\n",
    "\n",
    "    for _epoch in range(_num_epoch):\n",
    "        # train models\n",
    "        _model1.train()\n",
    "        _model2.train()\n",
    "\n",
    "        _train_acc1, _train_acc2, _pure_ratio_1_list, _pure_ratio_2_list = train(train_loader, _epoch, _model1, _optm1,\n",
    "                                                                                 _model2, _optm2, _criterion_select,\n",
    "                                                                                 _rate_schedule, _num_mixup_alpha,\n",
    "                                                                                 _iter_per_epoch)\n",
    "\n",
    "        if _learning_rate_scheduler_select == \"StepLR\":\n",
    "            scheduler1.step(_epoch)\n",
    "            scheduler2.step(_epoch)\n",
    "        else:\n",
    "            adjust_learning_rate(_optm1, _epoch)\n",
    "            adjust_learning_rate(_optm2, _epoch)\n",
    "\n",
    "        if (_epoch + 1) % _freq_evaluate == 0:\n",
    "            # evaluate models\n",
    "            _test_acc1, _test_acc2 = evaluate(test_loader, _model1, _model2)\n",
    "            # save results\n",
    "            if name_dataset == 'cifar10':\n",
    "                _mean_pure_ratio1 = sum(_pure_ratio_1_list) / len(_pure_ratio_1_list)\n",
    "                _mean_pure_ratio2 = sum(_pure_ratio_2_list) / len(_pure_ratio_2_list)\n",
    "                _str_ratio = 'Pure Ratio 1 %.4f %%, Pure Ratio 2 %.4f' % (_mean_pure_ratio1, _mean_pure_ratio2)\n",
    "            else:\n",
    "                _str_ratio = 'animal10n without pure ratio.'\n",
    "            print('Epoch [%d/%d] Test Accuracy on the %s test images: Model1 %.4f %% Model2 %.4f %%, %s' % (\n",
    "                _epoch + 1, num_epoch, len(test_loader.dataset), _test_acc1, _test_acc2, _str_ratio))\n",
    "\n",
    "            _temp_acc = max(_test_acc1, _test_acc2)  # current best testing accuracy\n",
    "            trial.report(_temp_acc, _epoch)\n",
    "            if trial.should_prune():\n",
    "                raise optuna.TrialPruned()\n",
    "            else:\n",
    "                print(\"Trial not pruned yet\")\n",
    "\n",
    "    return max(_test_acc1, _test_acc2)\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    #  _criterion_select = trial.suggest_categorical(\n",
    "    #      \"Criterion\",\n",
    "    #      [\"CEL\"])\n",
    "    _forget_rate_selection = trial.suggest_categorical(\n",
    "        \"Forget Rate\",\n",
    "        [0.05, 0.1, 0.2, 0.5])\n",
    "    _gradual = trial.suggest_categorical(\n",
    "        \"Gradual\",\n",
    "        [10, 50])\n",
    "    _mixup_alpha = trial.suggest_categorical(\n",
    "        \"Mixup Alpha\",\n",
    "        [0, 0.05, 0.1, 0.5])\n",
    "    _optm_select = trial.suggest_categorical(\n",
    "        \"Optimizer\",\n",
    "        [\"SGD\", \"Adam\"])\n",
    "    _lr_scheduler_select = trial.suggest_categorical(\n",
    "        \"Scheduler\",\n",
    "        [\"StepLR\", \"None\"]\n",
    "    )\n",
    "    _lr_select = trial.suggest_categorical(\n",
    "        \"Learning Rate\",\n",
    "        [0.08, 0.04, 0.02, 0.008, 0.004]\n",
    "    )\n",
    "    _model_select = trial.suggest_categorical(  # TODO: Search models for training\n",
    "        \"Model\",\n",
    "        [\"CNN\",\n",
    "         \"Densenet121\",\n",
    "         \"EfficientNet_v2_rw_t\"]\n",
    "    )\n",
    "\n",
    "    _accuracy = train_trial(_model_select,\n",
    "                            _optm_select,\n",
    "                            _lr_scheduler_select,\n",
    "                            trial=trial,\n",
    "                            _forget_rate=_forget_rate_selection, _gradual=_gradual, _num_epoch=200,\n",
    "                            _num_mixup_alpha=_mixup_alpha, _iter_per_epoch=200, _num_exponent=1, _learning_rate=0.04,\n",
    "                            _freq_evaluate=5, _freeze_weights=True)\n",
    "    return _accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Run the study here"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-03-19 23:17:38,826]\u001B[0m Using an existing study with name 'cifar10_Task1_2022_03_17' instead of creating a new one.\u001B[0m\n",
      "Using cache found in C:\\Users\\Wenda/.cache\\torch\\hub\\rwightman_pytorch-image-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start trail...\n",
      "building model...\n",
      "Loading pre-trained model: Densenet121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Wenda/.cache\\torch\\hub\\rwightman_pytorch-image-models_master\n",
      "C:\\Users\\Wenda\\anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current model: Densenet121, current optimizer: Adam, criterion: CrossEntropyLoss(), lr schedule: None, forget rate: 0.2, gradual rate: 50, mixup alpha: 0.5\n",
      "Training... cifar10_cifar10_noisy_labels_task1.json\n",
      "Train Epoch [1/200], Iter [100/3] Training Accuracy1: 13.4697, Training Accuracy2: 13.9403, Loss1: 9.3332, Loss2: 9.0899, Pure Ratio1: 63.5000, Pure Ratio2 63.5000\n",
      "Train Epoch [1/200], Iter [200/3] Training Accuracy1: 27.6615, Training Accuracy2: 28.2521, Loss1: 9.4970, Loss2: 9.7374, Pure Ratio1: 64.0742, Pure Ratio2 64.0742\n",
      "Training... cifar10_cifar10_noisy_labels_task1.json\n",
      "Train Epoch [2/200], Iter [100/3] Training Accuracy1: 15.0204, Training Accuracy2: 15.0169, Loss1: 9.1648, Loss2: 9.6623, Pure Ratio1: 64.3858, Pure Ratio2 64.4488\n",
      "Train Epoch [2/200], Iter [200/3] Training Accuracy1: 30.1312, Training Accuracy2: 30.3560, Loss1: 7.0412, Loss2: 7.4262, Pure Ratio1: 64.2520, Pure Ratio2 64.2598\n",
      "Training... cifar10_cifar10_noisy_labels_task1.json\n",
      "Train Epoch [3/200], Iter [100/3] Training Accuracy1: 15.2863, Training Accuracy2: 15.7053, Loss1: 6.6629, Loss2: 6.3753, Pure Ratio1: 64.1270, Pure Ratio2 64.0952\n",
      "Train Epoch [3/200], Iter [200/3] Training Accuracy1: 31.9895, Training Accuracy2: 32.2145, Loss1: 5.6947, Loss2: 5.7969, Pure Ratio1: 64.3849, Pure Ratio2 64.3294\n",
      "Training... cifar10_cifar10_noisy_labels_task1.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "study_trail = True\n",
    "\n",
    "if name_dataset == \"cifar10\":\n",
    "    study_name = f\"{name_dataset}_Task{id_task}_2022_03_17\"  # update the date manually here\n",
    "else:  # When the dataset is animal10n\n",
    "    study_name = name_dataset\n",
    "\n",
    "search_space = {\"Forget Rate\":[0.05, 0.1, 0.2, 0.5],\n",
    "                \"Gradual\":[10, 50],\n",
    "                \"Mixup Alpha\":[0, 0.05, 0.1, 0.5],\n",
    "                \"Optimizer\":[\"SGD\", \"Adam\"],\n",
    "                \"Scheduler\":[\"StepLR\", \"None\"],\n",
    "                \"Learning Rate\":[0.08, 0.04, 0.02, 0.008, 0.004],\n",
    "                \"Model\":[\"CNN\",\"Densenet121\",\"EfficientNet_v2_rw_t\"]\n",
    "                }\n",
    "# TODO: Configure MySQL DB for remote connection\n",
    "study = optuna.create_study(study_name=study_name,\n",
    "                            storage='mysql://root:1115@192.168.50.11:3306/co_mixing',\n",
    "                            load_if_exists=True,\n",
    "                            direction=\"maximize\",\n",
    "                            sampler=optuna.samplers.GridSampler(search_space))\n",
    "\n",
    "if study_trail:\n",
    "    study.optimize(objective, n_trials=200)\n",
    "    # pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "    # complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "    print(\"Facts:\")\n",
    "    print(\"  Finished Trials: \", len(study.trials))\n",
    "    # print(\"  Pruned Trials: \", len(pruned_trials))\n",
    "    # print(\"  Complete Trials: \", len(complete_trials))\n",
    "\n",
    "    print(\"Best Trial:\")\n",
    "    trial_best = study.best_trial\n",
    "    print(\"  Value: \", trial_best.value)\n",
    "    print(\"  Parameters: \")\n",
    "    for key, value in trial_best.params.items():\n",
    "        print(\"  {}: {}\".format(key, value))\n",
    "else:\n",
    "    train_trial(\"Mobilenet_v2_035\",\n",
    "                \"SGD\",\n",
    "                \"StepLR\",\n",
    "                _forget_rate=0.1, _gradual=10, _num_epoch=200, _num_mixup_alpha=0.1, _iter_per_epoch=200,\n",
    "                _num_exponent=1, _learning_rate=0.04, _freq_evaluate=5, _freeze_weights=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "modelA = torch.hub.load('rwightman/pytorch-image-models', 'tf_efficientnetv2_s_in21ft1k')\n",
    "modelB = torch.hub.load('rwightman/pytorch-image-models', 'tf_efficientnetv2_m_in21ft1k')\n",
    "modelA = modelA.to(device)\n",
    "modelB = modelB.to(device)\n",
    "\n",
    "_acc1, _acc2 = evaluate(test_loader, modelA, modelB)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Wenda/.cache\\torch\\hub\\rwightman_pytorch-image-models_master\n"
     ]
    },
    {
     "data": {
      "text/plain": "['adv_inception_v3',\n 'bat_resnext26ts',\n 'beit_base_patch16_224',\n 'beit_base_patch16_224_in22k',\n 'beit_base_patch16_384',\n 'beit_large_patch16_224',\n 'beit_large_patch16_224_in22k',\n 'beit_large_patch16_384',\n 'beit_large_patch16_512',\n 'botnet26t_256',\n 'botnet50ts_256',\n 'cait_m36_384',\n 'cait_m48_448',\n 'cait_s24_224',\n 'cait_s24_384',\n 'cait_s36_384',\n 'cait_xs24_384',\n 'cait_xxs24_224',\n 'cait_xxs24_384',\n 'cait_xxs36_224',\n 'cait_xxs36_384',\n 'coat_lite_mini',\n 'coat_lite_small',\n 'coat_lite_tiny',\n 'coat_mini',\n 'coat_tiny',\n 'convit_base',\n 'convit_small',\n 'convit_tiny',\n 'convmixer_1024_20_ks9_p14',\n 'convmixer_1536_20',\n 'convmixer_768_32',\n 'convnext_base',\n 'convnext_base_384_in22ft1k',\n 'convnext_base_in22ft1k',\n 'convnext_base_in22k',\n 'convnext_large',\n 'convnext_large_384_in22ft1k',\n 'convnext_large_in22ft1k',\n 'convnext_large_in22k',\n 'convnext_small',\n 'convnext_tiny',\n 'convnext_tiny_hnf',\n 'convnext_xlarge_384_in22ft1k',\n 'convnext_xlarge_in22ft1k',\n 'convnext_xlarge_in22k',\n 'crossvit_15_240',\n 'crossvit_15_dagger_240',\n 'crossvit_15_dagger_408',\n 'crossvit_18_240',\n 'crossvit_18_dagger_240',\n 'crossvit_18_dagger_408',\n 'crossvit_9_240',\n 'crossvit_9_dagger_240',\n 'crossvit_base_240',\n 'crossvit_small_240',\n 'crossvit_tiny_240',\n 'cspdarknet53',\n 'cspdarknet53_iabn',\n 'cspresnet50',\n 'cspresnet50d',\n 'cspresnet50w',\n 'cspresnext50',\n 'cspresnext50_iabn',\n 'darknet53',\n 'deit_base_distilled_patch16_224',\n 'deit_base_distilled_patch16_384',\n 'deit_base_patch16_224',\n 'deit_base_patch16_384',\n 'deit_small_distilled_patch16_224',\n 'deit_small_patch16_224',\n 'deit_tiny_distilled_patch16_224',\n 'deit_tiny_patch16_224',\n 'densenet121',\n 'densenet121d',\n 'densenet161',\n 'densenet169',\n 'densenet201',\n 'densenet264',\n 'densenet264d_iabn',\n 'densenetblur121d',\n 'dla102',\n 'dla102x',\n 'dla102x2',\n 'dla169',\n 'dla34',\n 'dla46_c',\n 'dla46x_c',\n 'dla60',\n 'dla60_res2net',\n 'dla60_res2next',\n 'dla60x',\n 'dla60x_c',\n 'dm_nfnet_f0',\n 'dm_nfnet_f1',\n 'dm_nfnet_f2',\n 'dm_nfnet_f3',\n 'dm_nfnet_f4',\n 'dm_nfnet_f5',\n 'dm_nfnet_f6',\n 'dpn107',\n 'dpn131',\n 'dpn68',\n 'dpn68b',\n 'dpn92',\n 'dpn98',\n 'eca_botnext26ts_256',\n 'eca_halonext26ts',\n 'eca_nfnet_l0',\n 'eca_nfnet_l1',\n 'eca_nfnet_l2',\n 'eca_nfnet_l3',\n 'eca_resnet33ts',\n 'eca_resnext26ts',\n 'eca_vovnet39b',\n 'ecaresnet101d',\n 'ecaresnet101d_pruned',\n 'ecaresnet200d',\n 'ecaresnet269d',\n 'ecaresnet26t',\n 'ecaresnet50d',\n 'ecaresnet50d_pruned',\n 'ecaresnet50t',\n 'ecaresnetlight',\n 'ecaresnext26t_32x4d',\n 'ecaresnext50t_32x4d',\n 'efficientnet_b0',\n 'efficientnet_b1',\n 'efficientnet_b1_pruned',\n 'efficientnet_b2',\n 'efficientnet_b2_pruned',\n 'efficientnet_b2a',\n 'efficientnet_b3',\n 'efficientnet_b3_pruned',\n 'efficientnet_b3a',\n 'efficientnet_b4',\n 'efficientnet_b5',\n 'efficientnet_b6',\n 'efficientnet_b7',\n 'efficientnet_b8',\n 'efficientnet_cc_b0_4e',\n 'efficientnet_cc_b0_8e',\n 'efficientnet_cc_b1_8e',\n 'efficientnet_el',\n 'efficientnet_el_pruned',\n 'efficientnet_em',\n 'efficientnet_es',\n 'efficientnet_es_pruned',\n 'efficientnet_l2',\n 'efficientnet_lite0',\n 'efficientnet_lite1',\n 'efficientnet_lite2',\n 'efficientnet_lite3',\n 'efficientnet_lite4',\n 'efficientnetv2_l',\n 'efficientnetv2_m',\n 'efficientnetv2_rw_m',\n 'efficientnetv2_rw_s',\n 'efficientnetv2_rw_t',\n 'efficientnetv2_s',\n 'efficientnetv2_xl',\n 'ens_adv_inception_resnet_v2',\n 'ese_vovnet19b_dw',\n 'ese_vovnet19b_slim',\n 'ese_vovnet19b_slim_dw',\n 'ese_vovnet39b',\n 'ese_vovnet39b_evos',\n 'ese_vovnet57b',\n 'ese_vovnet99b',\n 'ese_vovnet99b_iabn',\n 'fbnetc_100',\n 'fbnetv3_b',\n 'fbnetv3_d',\n 'fbnetv3_g',\n 'gc_efficientnetv2_rw_t',\n 'gcresnet33ts',\n 'gcresnet50t',\n 'gcresnext26ts',\n 'gcresnext50ts',\n 'gernet_l',\n 'gernet_m',\n 'gernet_s',\n 'ghostnet_050',\n 'ghostnet_100',\n 'ghostnet_130',\n 'gluon_inception_v3',\n 'gluon_resnet101_v1b',\n 'gluon_resnet101_v1c',\n 'gluon_resnet101_v1d',\n 'gluon_resnet101_v1s',\n 'gluon_resnet152_v1b',\n 'gluon_resnet152_v1c',\n 'gluon_resnet152_v1d',\n 'gluon_resnet152_v1s',\n 'gluon_resnet18_v1b',\n 'gluon_resnet34_v1b',\n 'gluon_resnet50_v1b',\n 'gluon_resnet50_v1c',\n 'gluon_resnet50_v1d',\n 'gluon_resnet50_v1s',\n 'gluon_resnext101_32x4d',\n 'gluon_resnext101_64x4d',\n 'gluon_resnext50_32x4d',\n 'gluon_senet154',\n 'gluon_seresnext101_32x4d',\n 'gluon_seresnext101_64x4d',\n 'gluon_seresnext50_32x4d',\n 'gluon_xception65',\n 'gmixer_12_224',\n 'gmixer_24_224',\n 'gmlp_b16_224',\n 'gmlp_s16_224',\n 'gmlp_ti16_224',\n 'halo2botnet50ts_256',\n 'halonet26t',\n 'halonet50ts',\n 'halonet_h1',\n 'haloregnetz_b',\n 'hardcorenas_a',\n 'hardcorenas_b',\n 'hardcorenas_c',\n 'hardcorenas_d',\n 'hardcorenas_e',\n 'hardcorenas_f',\n 'hrnet_w18',\n 'hrnet_w18_small',\n 'hrnet_w18_small_v2',\n 'hrnet_w30',\n 'hrnet_w32',\n 'hrnet_w40',\n 'hrnet_w44',\n 'hrnet_w48',\n 'hrnet_w64',\n 'ig_resnext101_32x16d',\n 'ig_resnext101_32x32d',\n 'ig_resnext101_32x48d',\n 'ig_resnext101_32x8d',\n 'inception_resnet_v2',\n 'inception_v3',\n 'inception_v4',\n 'jx_nest_base',\n 'jx_nest_small',\n 'jx_nest_tiny',\n 'lambda_resnet26rpt_256',\n 'lambda_resnet26t',\n 'lambda_resnet50ts',\n 'lamhalobotnet50ts_256',\n 'lcnet_035',\n 'lcnet_050',\n 'lcnet_075',\n 'lcnet_100',\n 'lcnet_150',\n 'legacy_senet154',\n 'legacy_seresnet101',\n 'legacy_seresnet152',\n 'legacy_seresnet18',\n 'legacy_seresnet34',\n 'legacy_seresnet50',\n 'legacy_seresnext101_32x4d',\n 'legacy_seresnext26_32x4d',\n 'legacy_seresnext50_32x4d',\n 'levit_128',\n 'levit_128s',\n 'levit_192',\n 'levit_256',\n 'levit_384',\n 'mixer_b16_224',\n 'mixer_b16_224_in21k',\n 'mixer_b16_224_miil',\n 'mixer_b16_224_miil_in21k',\n 'mixer_b32_224',\n 'mixer_l16_224',\n 'mixer_l16_224_in21k',\n 'mixer_l32_224',\n 'mixer_s16_224',\n 'mixer_s32_224',\n 'mixnet_l',\n 'mixnet_m',\n 'mixnet_s',\n 'mixnet_xl',\n 'mixnet_xxl',\n 'mnasnet_050',\n 'mnasnet_075',\n 'mnasnet_100',\n 'mnasnet_140',\n 'mnasnet_a1',\n 'mnasnet_b1',\n 'mnasnet_small',\n 'mobilenetv2_035',\n 'mobilenetv2_050',\n 'mobilenetv2_075',\n 'mobilenetv2_100',\n 'mobilenetv2_110d',\n 'mobilenetv2_120d',\n 'mobilenetv2_140',\n 'mobilenetv3_large_075',\n 'mobilenetv3_large_100',\n 'mobilenetv3_large_100_miil',\n 'mobilenetv3_large_100_miil_in21k',\n 'mobilenetv3_rw',\n 'mobilenetv3_small_050',\n 'mobilenetv3_small_075',\n 'mobilenetv3_small_100',\n 'nasnetalarge',\n 'nest_base',\n 'nest_small',\n 'nest_tiny',\n 'nf_ecaresnet101',\n 'nf_ecaresnet26',\n 'nf_ecaresnet50',\n 'nf_regnet_b0',\n 'nf_regnet_b1',\n 'nf_regnet_b2',\n 'nf_regnet_b3',\n 'nf_regnet_b4',\n 'nf_regnet_b5',\n 'nf_resnet101',\n 'nf_resnet26',\n 'nf_resnet50',\n 'nf_seresnet101',\n 'nf_seresnet26',\n 'nf_seresnet50',\n 'nfnet_f0',\n 'nfnet_f0s',\n 'nfnet_f1',\n 'nfnet_f1s',\n 'nfnet_f2',\n 'nfnet_f2s',\n 'nfnet_f3',\n 'nfnet_f3s',\n 'nfnet_f4',\n 'nfnet_f4s',\n 'nfnet_f5',\n 'nfnet_f5s',\n 'nfnet_f6',\n 'nfnet_f6s',\n 'nfnet_f7',\n 'nfnet_f7s',\n 'nfnet_l0',\n 'pit_b_224',\n 'pit_b_distilled_224',\n 'pit_s_224',\n 'pit_s_distilled_224',\n 'pit_ti_224',\n 'pit_ti_distilled_224',\n 'pit_xs_224',\n 'pit_xs_distilled_224',\n 'pnasnet5large',\n 'regnetx_002',\n 'regnetx_004',\n 'regnetx_006',\n 'regnetx_008',\n 'regnetx_016',\n 'regnetx_032',\n 'regnetx_040',\n 'regnetx_064',\n 'regnetx_080',\n 'regnetx_120',\n 'regnetx_160',\n 'regnetx_320',\n 'regnety_002',\n 'regnety_004',\n 'regnety_006',\n 'regnety_008',\n 'regnety_016',\n 'regnety_032',\n 'regnety_040',\n 'regnety_064',\n 'regnety_080',\n 'regnety_120',\n 'regnety_160',\n 'regnety_320',\n 'regnetz_b16',\n 'regnetz_c16',\n 'regnetz_d32',\n 'regnetz_d8',\n 'regnetz_d8_evob',\n 'regnetz_d8_evos',\n 'regnetz_e8',\n 'repvgg_a2',\n 'repvgg_b0',\n 'repvgg_b1',\n 'repvgg_b1g4',\n 'repvgg_b2',\n 'repvgg_b2g4',\n 'repvgg_b3',\n 'repvgg_b3g4',\n 'res2net101_26w_4s',\n 'res2net50_14w_8s',\n 'res2net50_26w_4s',\n 'res2net50_26w_6s',\n 'res2net50_26w_8s',\n 'res2net50_48w_2s',\n 'res2next50',\n 'resmlp_12_224',\n 'resmlp_12_224_dino',\n 'resmlp_12_distilled_224',\n 'resmlp_24_224',\n 'resmlp_24_224_dino',\n 'resmlp_24_distilled_224',\n 'resmlp_36_224',\n 'resmlp_36_distilled_224',\n 'resmlp_big_24_224',\n 'resmlp_big_24_224_in22ft1k',\n 'resmlp_big_24_distilled_224',\n 'resnest101e',\n 'resnest14d',\n 'resnest200e',\n 'resnest269e',\n 'resnest26d',\n 'resnest50d',\n 'resnest50d_1s4x24d',\n 'resnest50d_4s2x40d',\n 'resnet101',\n 'resnet101d',\n 'resnet152',\n 'resnet152d',\n 'resnet18',\n 'resnet18d',\n 'resnet200',\n 'resnet200d',\n 'resnet26',\n 'resnet26d',\n 'resnet26t',\n 'resnet32ts',\n 'resnet33ts',\n 'resnet34',\n 'resnet34d',\n 'resnet50',\n 'resnet50_gn',\n 'resnet50d',\n 'resnet50t',\n 'resnet51q',\n 'resnet61q',\n 'resnetaa101d',\n 'resnetaa50d',\n 'resnetblur101d',\n 'resnetblur18',\n 'resnetblur50',\n 'resnetblur50d',\n 'resnetrs101',\n 'resnetrs152',\n 'resnetrs200',\n 'resnetrs270',\n 'resnetrs350',\n 'resnetrs420',\n 'resnetrs50',\n 'resnetv2_101',\n 'resnetv2_101d',\n 'resnetv2_101x1_bitm',\n 'resnetv2_101x1_bitm_in21k',\n 'resnetv2_101x3_bitm',\n 'resnetv2_101x3_bitm_in21k',\n 'resnetv2_152',\n 'resnetv2_152d',\n 'resnetv2_152x2_bit_teacher',\n 'resnetv2_152x2_bit_teacher_384',\n 'resnetv2_152x2_bitm',\n 'resnetv2_152x2_bitm_in21k',\n 'resnetv2_152x4_bitm',\n 'resnetv2_152x4_bitm_in21k',\n 'resnetv2_50',\n 'resnetv2_50d',\n 'resnetv2_50d_evob',\n 'resnetv2_50d_evos',\n 'resnetv2_50d_gn',\n 'resnetv2_50t',\n 'resnetv2_50x1_bit_distilled',\n 'resnetv2_50x1_bitm',\n 'resnetv2_50x1_bitm_in21k',\n 'resnetv2_50x3_bitm',\n 'resnetv2_50x3_bitm_in21k',\n 'resnext101_32x4d',\n 'resnext101_32x8d',\n 'resnext101_64x4d',\n 'resnext26ts',\n 'resnext50_32x4d',\n 'resnext50d_32x4d',\n 'rexnet_100',\n 'rexnet_130',\n 'rexnet_150',\n 'rexnet_200',\n 'rexnetr_100',\n 'rexnetr_130',\n 'rexnetr_150',\n 'rexnetr_200',\n 'sebotnet33ts_256',\n 'sehalonet33ts',\n 'selecsls42',\n 'selecsls42b',\n 'selecsls60',\n 'selecsls60b',\n 'selecsls84',\n 'semnasnet_050',\n 'semnasnet_075',\n 'semnasnet_100',\n 'semnasnet_140',\n 'senet154',\n 'seresnet101',\n 'seresnet152',\n 'seresnet152d',\n 'seresnet18',\n 'seresnet200d',\n 'seresnet269d',\n 'seresnet33ts',\n 'seresnet34',\n 'seresnet50',\n 'seresnet50t',\n 'seresnetaa50d',\n 'seresnext101_32x4d',\n 'seresnext101_32x8d',\n 'seresnext26d_32x4d',\n 'seresnext26t_32x4d',\n 'seresnext26tn_32x4d',\n 'seresnext26ts',\n 'seresnext50_32x4d',\n 'skresnet18',\n 'skresnet34',\n 'skresnet50',\n 'skresnet50d',\n 'skresnext50_32x4d',\n 'spnasnet_100',\n 'ssl_resnet18',\n 'ssl_resnet50',\n 'ssl_resnext101_32x16d',\n 'ssl_resnext101_32x4d',\n 'ssl_resnext101_32x8d',\n 'ssl_resnext50_32x4d',\n 'swin_base_patch4_window12_384',\n 'swin_base_patch4_window12_384_in22k',\n 'swin_base_patch4_window7_224',\n 'swin_base_patch4_window7_224_in22k',\n 'swin_large_patch4_window12_384',\n 'swin_large_patch4_window12_384_in22k',\n 'swin_large_patch4_window7_224',\n 'swin_large_patch4_window7_224_in22k',\n 'swin_small_patch4_window7_224',\n 'swin_tiny_patch4_window7_224',\n 'swsl_resnet18',\n 'swsl_resnet50',\n 'swsl_resnext101_32x16d',\n 'swsl_resnext101_32x4d',\n 'swsl_resnext101_32x8d',\n 'swsl_resnext50_32x4d',\n 'tf_efficientnet_b0',\n 'tf_efficientnet_b0_ap',\n 'tf_efficientnet_b0_ns',\n 'tf_efficientnet_b1',\n 'tf_efficientnet_b1_ap',\n 'tf_efficientnet_b1_ns',\n 'tf_efficientnet_b2',\n 'tf_efficientnet_b2_ap',\n 'tf_efficientnet_b2_ns',\n 'tf_efficientnet_b3',\n 'tf_efficientnet_b3_ap',\n 'tf_efficientnet_b3_ns',\n 'tf_efficientnet_b4',\n 'tf_efficientnet_b4_ap',\n 'tf_efficientnet_b4_ns',\n 'tf_efficientnet_b5',\n 'tf_efficientnet_b5_ap',\n 'tf_efficientnet_b5_ns',\n 'tf_efficientnet_b6',\n 'tf_efficientnet_b6_ap',\n 'tf_efficientnet_b6_ns',\n 'tf_efficientnet_b7',\n 'tf_efficientnet_b7_ap',\n 'tf_efficientnet_b7_ns',\n 'tf_efficientnet_b8',\n 'tf_efficientnet_b8_ap',\n 'tf_efficientnet_cc_b0_4e',\n 'tf_efficientnet_cc_b0_8e',\n 'tf_efficientnet_cc_b1_8e',\n 'tf_efficientnet_el',\n 'tf_efficientnet_em',\n 'tf_efficientnet_es',\n 'tf_efficientnet_l2_ns',\n 'tf_efficientnet_l2_ns_475',\n 'tf_efficientnet_lite0',\n 'tf_efficientnet_lite1',\n 'tf_efficientnet_lite2',\n 'tf_efficientnet_lite3',\n 'tf_efficientnet_lite4',\n 'tf_efficientnetv2_b0',\n 'tf_efficientnetv2_b1',\n 'tf_efficientnetv2_b2',\n 'tf_efficientnetv2_b3',\n 'tf_efficientnetv2_l',\n 'tf_efficientnetv2_l_in21ft1k',\n 'tf_efficientnetv2_l_in21k',\n 'tf_efficientnetv2_m',\n 'tf_efficientnetv2_m_in21ft1k',\n 'tf_efficientnetv2_m_in21k',\n 'tf_efficientnetv2_s',\n 'tf_efficientnetv2_s_in21ft1k',\n 'tf_efficientnetv2_s_in21k',\n 'tf_efficientnetv2_xl_in21ft1k',\n 'tf_efficientnetv2_xl_in21k',\n 'tf_inception_v3',\n 'tf_mixnet_l',\n 'tf_mixnet_m',\n 'tf_mixnet_s',\n 'tf_mobilenetv3_large_075',\n 'tf_mobilenetv3_large_100',\n 'tf_mobilenetv3_large_minimal_100',\n 'tf_mobilenetv3_small_075',\n 'tf_mobilenetv3_small_100',\n 'tf_mobilenetv3_small_minimal_100',\n 'tinynet_a',\n 'tinynet_b',\n 'tinynet_c',\n 'tinynet_d',\n 'tinynet_e',\n 'tnt_b_patch16_224',\n 'tnt_s_patch16_224',\n 'tresnet_l',\n 'tresnet_l_448',\n 'tresnet_m',\n 'tresnet_m_448',\n 'tresnet_m_miil_in21k',\n 'tresnet_xl',\n 'tresnet_xl_448',\n 'tv_densenet121',\n 'tv_resnet101',\n 'tv_resnet152',\n 'tv_resnet34',\n 'tv_resnet50',\n 'tv_resnext50_32x4d',\n 'twins_pcpvt_base',\n 'twins_pcpvt_large',\n 'twins_pcpvt_small',\n 'twins_svt_base',\n 'twins_svt_large',\n 'twins_svt_small',\n 'vgg11',\n 'vgg11_bn',\n 'vgg13',\n 'vgg13_bn',\n 'vgg16',\n 'vgg16_bn',\n 'vgg19',\n 'vgg19_bn',\n 'visformer_small',\n 'visformer_tiny',\n 'vit_base2_patch32_256',\n 'vit_base_patch16_224',\n 'vit_base_patch16_224_dino',\n 'vit_base_patch16_224_in21k',\n 'vit_base_patch16_224_miil',\n 'vit_base_patch16_224_miil_in21k',\n 'vit_base_patch16_224_sam',\n 'vit_base_patch16_384',\n 'vit_base_patch32_224',\n 'vit_base_patch32_224_in21k',\n 'vit_base_patch32_224_sam',\n 'vit_base_patch32_384',\n 'vit_base_patch8_224',\n 'vit_base_patch8_224_dino',\n 'vit_base_patch8_224_in21k',\n 'vit_base_r26_s32_224',\n 'vit_base_r50_s16_224',\n 'vit_base_r50_s16_224_in21k',\n 'vit_base_r50_s16_384',\n 'vit_base_resnet26d_224',\n 'vit_base_resnet50_224_in21k',\n 'vit_base_resnet50_384',\n 'vit_base_resnet50d_224',\n 'vit_giant_patch14_224',\n 'vit_gigantic_patch14_224',\n 'vit_huge_patch14_224',\n 'vit_huge_patch14_224_in21k',\n 'vit_large_patch16_224',\n 'vit_large_patch16_224_in21k',\n 'vit_large_patch16_384',\n 'vit_large_patch32_224',\n 'vit_large_patch32_224_in21k',\n 'vit_large_patch32_384',\n 'vit_large_r50_s32_224',\n 'vit_large_r50_s32_224_in21k',\n 'vit_large_r50_s32_384',\n 'vit_small_patch16_224',\n 'vit_small_patch16_224_dino',\n 'vit_small_patch16_224_in21k',\n 'vit_small_patch16_384',\n 'vit_small_patch32_224',\n 'vit_small_patch32_224_in21k',\n 'vit_small_patch32_384',\n 'vit_small_patch8_224_dino',\n 'vit_small_r26_s32_224',\n 'vit_small_r26_s32_224_in21k',\n 'vit_small_r26_s32_384',\n 'vit_small_resnet26d_224',\n 'vit_small_resnet50d_s16_224',\n 'vit_tiny_patch16_224',\n 'vit_tiny_patch16_224_in21k',\n 'vit_tiny_patch16_384',\n 'vit_tiny_r_s16_p8_224',\n 'vit_tiny_r_s16_p8_224_in21k',\n 'vit_tiny_r_s16_p8_384',\n 'vovnet39a',\n 'vovnet57a',\n 'wide_resnet101_2',\n 'wide_resnet50_2',\n 'xception',\n 'xception41',\n 'xception65',\n 'xception71',\n 'xcit_large_24_p16_224',\n 'xcit_large_24_p16_224_dist',\n 'xcit_large_24_p16_384_dist',\n 'xcit_large_24_p8_224',\n 'xcit_large_24_p8_224_dist',\n 'xcit_large_24_p8_384_dist',\n 'xcit_medium_24_p16_224',\n 'xcit_medium_24_p16_224_dist',\n 'xcit_medium_24_p16_384_dist',\n 'xcit_medium_24_p8_224',\n 'xcit_medium_24_p8_224_dist',\n 'xcit_medium_24_p8_384_dist',\n 'xcit_nano_12_p16_224',\n 'xcit_nano_12_p16_224_dist',\n 'xcit_nano_12_p16_384_dist',\n 'xcit_nano_12_p8_224',\n 'xcit_nano_12_p8_224_dist',\n 'xcit_nano_12_p8_384_dist',\n 'xcit_small_12_p16_224',\n 'xcit_small_12_p16_224_dist',\n 'xcit_small_12_p16_384_dist',\n 'xcit_small_12_p8_224',\n 'xcit_small_12_p8_224_dist',\n 'xcit_small_12_p8_384_dist',\n 'xcit_small_24_p16_224',\n 'xcit_small_24_p16_224_dist',\n 'xcit_small_24_p16_384_dist',\n 'xcit_small_24_p8_224',\n 'xcit_small_24_p8_224_dist',\n 'xcit_small_24_p8_384_dist',\n 'xcit_tiny_12_p16_224',\n 'xcit_tiny_12_p16_224_dist',\n 'xcit_tiny_12_p16_384_dist',\n 'xcit_tiny_12_p8_224',\n 'xcit_tiny_12_p8_224_dist',\n 'xcit_tiny_12_p8_384_dist',\n 'xcit_tiny_24_p16_224',\n 'xcit_tiny_24_p16_224_dist',\n 'xcit_tiny_24_p16_384_dist',\n 'xcit_tiny_24_p8_224',\n 'xcit_tiny_24_p8_224_dist',\n 'xcit_tiny_24_p8_384_dist']"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.hub.list('rwightman/pytorch-image-models')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "from model import ReshapedPreTrainedModel, modify_pretrained_outputs\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.empty_cache()\n",
    "modelC = torch.hub.load('rwightman/pytorch-image-models', 'mobilenetv2_100', pretrained=True)\n",
    "\n",
    "\n",
    "\n",
    "# modelC = ReshapedPreTrainedModel(modelC, n_outputs=10, dropout_rate=0.25, freeze_weights=True)\n",
    "# modelC.to(device)\n",
    "# modelC = modify_pretrained_outputs(modelC)\n",
    "# modelC\n",
    "# modelC = modify_pretrained_outputs(modelC)\n",
    "summary(modelC.to(device), input_size=(3, 32, 32))\n",
    "modelC\n",
    "# modelC.to(device)\n",
    "#\n",
    "# image, label = next(iter(test_loader))\n",
    "# image = image.to(device)\n",
    "# out = modelC(image)\n",
    "#\n",
    "# print(out.size())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "study = optuna.load_study(study_name=\"cifar10_1\",\n",
    "                          storage='mysql://root:1115@192.168.50.11:3306/co_mixing')\n",
    "print(study.best_params)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "optuna.delete_study(study_name=\"cifar10_Task1_2022_03_17\",\n",
    "                    storage='mysql://root:1115@192.168.50.11:3306/co_mixing')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}