{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from model import CNN\n",
    "from loss import loss_coteaching\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from mixup import mixup_data\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from loader_CIFAR import CifarDataloader, CifarDataset, unpickle\n",
    "from loader_ANIMAL10N import Animal10N\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "\n",
    "# test the custom loaders for CIFAR\n",
    "dataset = 'animal10n'  # either cifar10 or animal10n\n",
    "data_path_animal = 'rawdata_ANIMAL10N'\n",
    "data_path = 'rawdata_CIFAR10'  # path to the data file (don't forget to download the feature data and also put the noisy label file under this folder)\n",
    "\n",
    "num_iter_per_epoch = 100\n",
    "num_print_freq = 100\n",
    "num_epoch = 200\n",
    "num_batch_size = 16\n",
    "num_gradual = 10\n",
    "num_exponent = 1\n",
    "num_forget_rate = 0.1\n",
    "num_noise_rate = 0.2\n",
    "num_workers = 8\n",
    "num_classes = 10\n",
    "num_learning_rate = 0.001\n",
    "num_input_channel = 3\n",
    "\n",
    "# Adjust learning rate and betas for Adam Optimizer\n",
    "num_mixup_alpha = 0.1\n",
    "num_epoch_decay_start = 80\n",
    "mom1 = 0.9\n",
    "mom2 = 0.1\n",
    "alpha_plan = [num_learning_rate] * num_epoch\n",
    "beta1_plan = [mom1] * num_epoch\n",
    "for i in range(num_epoch_decay_start, num_epoch):\n",
    "    alpha_plan[i] = float(num_epoch - i) / (num_epoch - num_epoch_decay_start) * num_learning_rate\n",
    "    beta1_plan[i] = mom2\n",
    "\n",
    "rate_schedule = np.ones(num_epoch) * num_forget_rate\n",
    "rate_schedule[:num_gradual] = np.linspace(0, num_forget_rate ** num_exponent, num_gradual)\n",
    "\n",
    "json_noise_file_names = {\n",
    "    1: 'cifar10_noisy_labels_task1.json',\n",
    "    2: 'cifar10_noisy_labels_task2.json',\n",
    "    3: 'cifar10_noisy_labels_task3.json'\n",
    "}\n",
    "noise_file_name = json_noise_file_names[1]\n",
    "\n",
    "if dataset == 'cifar10':\n",
    "    loader = CifarDataloader(dataset, batch_size=128,\n",
    "                             num_workers=10,\n",
    "                             root_dir=data_path,\n",
    "                             noise_file='%s/%s' % (data_path, noise_file_name))\n",
    "    train_loader, noisy_labels, clean_labels = loader.run('train')\n",
    "    noise_or_not = np.transpose(noisy_labels) == np.transpose(clean_labels)\n",
    "    test_loader = loader.run('test')\n",
    "else:\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    dataset_train = Animal10N(split='train', transform=transform_train)\n",
    "    dataset_test = Animal10N(split='test', transform=transform_test)\n",
    "\n",
    "    train_loader = DataLoader(dataset_train, batch_size=num_batch_size, shuffle=True, num_workers=num_workers)\n",
    "    test_loader = DataLoader(dataset_test, batch_size=num_batch_size * 2, shuffle=False, num_workers=num_workers)\n",
    "    noise_or_not = None\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_full_name = f'{dataset}_{noise_file_name}'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr']=alpha_plan[epoch]\n",
    "        param_group['betas']=(beta1_plan[epoch], 0.999) # Only change beta1\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# TODO: Complete migrating the Co-Teaching model\n",
    "def accuracy(logit, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    output = F.softmax(logit, dim=1)\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "\n",
    "def train(loader_train, epoch, model1, optimizer1, model2, optimizer2, criterion, _rate_schedule, _mixup_alpha, _iter_per_epoch):\n",
    "    print(\"Training... %s\" % model_full_name)\n",
    "    pure_ratio_list = []\n",
    "    pure_ratio_1_list = []\n",
    "    pure_ratio_2_list = []\n",
    "    count_total_train1 = 0\n",
    "    count_total_correct1 = 0\n",
    "    count_total_train2 = 0\n",
    "    count_total_correct2 = 0\n",
    "    num_correct_1 = 0\n",
    "    num_correct_2 = 0\n",
    "    num_total = 0\n",
    "\n",
    "    for i, (images, labels, indexes) in enumerate(loader_train):\n",
    "        ind = indexes.cpu().numpy().transpose()\n",
    "        if i > _iter_per_epoch > 0:\n",
    "            break\n",
    "\n",
    "        images = Variable(images).to(device)\n",
    "        labels = Variable(labels).to(device)\n",
    "        num_total = labels.size(0)\n",
    "\n",
    "        images, label_a, label_b, lam = mixup_data(images, labels, _mixup_alpha, True)\n",
    "\n",
    "        # Forward Backward Optimize\n",
    "        output1 = model1(images)\n",
    "        _, predicted1 = torch.max(output1.data, 1)\n",
    "        prec1, _ = accuracy(output1, labels, topk=(1, 5))\n",
    "        count_total_train1 += 1\n",
    "        count_total_correct1 += prec1\n",
    "\n",
    "        output2 = model2(images)\n",
    "        _, predicted2 = torch.max(output2.data, 1)\n",
    "        prec2, _ = accuracy(output2, labels, topk=(1, 5))\n",
    "        count_total_train2 += 1\n",
    "        count_total_correct2 += prec2\n",
    "\n",
    "        num_correct_1 += (lam * predicted1.eq(label_a.data).cpu().sum().float()\n",
    "                    + (1 - lam) * predicted1.eq(label_b.data).cpu().sum().float())\n",
    "        num_correct_2 += (lam * predicted2.eq(label_a.data).cpu().sum().float()\n",
    "                          + (1 - lam) * predicted2.eq(label_b.data).cpu().sum().float())\n",
    "        num_acc_1 = num_correct_1 / num_total\n",
    "        num_acc_2 = num_correct_2 / num_total\n",
    "\n",
    "        loss1, loss2, pure_ratio_1, pure_ratio_2 = loss_coteaching(criterion, output1, output2, labels, label_a, label_b, _rate_schedule[epoch], ind, noise_or_not, lam)\n",
    "\n",
    "        if pure_ratio_1 and pure_ratio_2 is not None:\n",
    "            pure_ratio_1_list.append(100*pure_ratio_1)\n",
    "            pure_ratio_2_list.append(100*pure_ratio_2)\n",
    "\n",
    "        optimizer1.zero_grad()\n",
    "        loss1.backward()\n",
    "        optimizer1.step()\n",
    "        optimizer2.zero_grad()\n",
    "        loss2.backward()\n",
    "        optimizer2.step()\n",
    "        if (i + 1) % num_print_freq == 0:\n",
    "            if pure_ratio_1 and pure_ratio_2 is not None:\n",
    "                str_calc_pure_ratio = 'Pure Ratio1: %.4f, Pure Ratio2 %.4f' % (np.sum(pure_ratio_1_list) / len(pure_ratio_1_list),\n",
    "                                                                               np.sum(pure_ratio_2_list) / len(pure_ratio_2_list))\n",
    "            else:\n",
    "                str_calc_pure_ratio = 'Animal10N dataset without pure ratio'\n",
    "\n",
    "            print(\n",
    "                'Train Epoch [%d/%d], Iter [%d/%d] Training Accuracy1: %.4F, Training Accuracy2: %.4f, Loss1: %.4f, Loss2: %.4f, %s'\n",
    "                % (epoch + 1, num_epoch, i + 1, len(train_loader) // num_batch_size, num_acc_1, num_acc_2, loss1.item(),\n",
    "                   loss2.item(), str_calc_pure_ratio))\n",
    "\n",
    "    train_acc1 = float(count_total_correct1) / float(count_total_train1)\n",
    "    train_acc2 = float(count_total_correct2) / float(count_total_train2)\n",
    "    return train_acc1, train_acc2, pure_ratio_1_list, pure_ratio_2_list\n",
    "\n",
    "\n",
    "def evaluate(test_loader, model1, model2):\n",
    "    print('Evaluating %s...' % model_full_name)\n",
    "    # model1 = model1.to(device)  # Change model to 'eval' mode.\n",
    "    # model2 = model2.to(device)\n",
    "    correct1 = 0\n",
    "    total1 = 0\n",
    "    print(\"Start evaluating model 1\")\n",
    "    for images, labels in test_loader:\n",
    "        images = Variable(images).to(device)\n",
    "        labels = labels.to(device)\n",
    "        logits1 = model1(images)\n",
    "        outputs1 = F.softmax(logits1, dim=1)\n",
    "        _, pred1 = torch.max(outputs1.data, 1)\n",
    "        total1 += labels.size(0)\n",
    "        correct1 += (pred1 == labels).sum()\n",
    "\n",
    "    print(\"Start evaluating model 2\")\n",
    "    model2.eval()  # Change model to 'eval' mode\n",
    "    correct2 = 0\n",
    "    total2 = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = Variable(images).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        logits2 = model2(images)\n",
    "        outputs2 = F.softmax(logits2, dim=1)\n",
    "        _, pred2 = torch.max(outputs2.data, 1)\n",
    "        total2 += labels.size(0)\n",
    "        correct2 += (pred2 == labels).sum()\n",
    "\n",
    "    acc1 = 100 * float(correct1) / float(total1)\n",
    "    acc2 = 100 * float(correct2) / float(total2)\n",
    "    return acc1, acc2\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset...\n",
      "building model...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'collections.OrderedDict' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-35-5bb1678e2370>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     43\u001B[0m \u001B[1;31m# evaluate models with random weights\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     44\u001B[0m \u001B[0mcnn1\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"models/efficientnet_v2_m-dc08266a.pth\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 45\u001B[1;33m \u001B[0mcnn1\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcnn1\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     46\u001B[0m \u001B[0mcnn2\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"models/efficientnet_v2_m-dc08266a.pth\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[0mcnn2\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcnn2\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'collections.OrderedDict' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "# Data Loader (Input Pipeline)\n",
    "print('loading dataset...')\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "#                                            batch_size=num_batch_size,\n",
    "#                                            num_workers=num_workers,\n",
    "#                                            drop_last=True,\n",
    "#                                            shuffle=True)\n",
    "#\n",
    "# test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "#                                           batch_size=num_batch_size,\n",
    "#                                           num_workers=num_workers,\n",
    "#                                           drop_last=True,\n",
    "#                                           shuffle=False)\n",
    "\n",
    "\n",
    "# Define models\n",
    "print('building model...')\n",
    "cnn1 = CNN(input_channel=num_input_channel, n_outputs=num_classes)\n",
    "cnn1.to(device)\n",
    "# print(cnn1.parameters)\n",
    "optimizer1 = torch.optim.Adam(cnn1.parameters(), lr=num_learning_rate)\n",
    "\n",
    "cnn2 = CNN(input_channel=num_input_channel, n_outputs=num_classes)\n",
    "cnn2.to(device)\n",
    "# print(cnn2.parameters)\n",
    "optimizer2 = torch.optim.Adam(cnn2.parameters(), lr=num_learning_rate)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss(reduce=False)\n",
    "mean_pure_ratio1=0\n",
    "mean_pure_ratio2=0\n",
    "\n",
    "# with open(txtfile, \"a\") as myfile:\n",
    "#     myfile.write('epoch: train_acc1 train_acc2 test_acc1 test_acc2 pure_ratio1 pure_ratio2\\n')\n",
    "\n",
    "epoch=0\n",
    "train_acc1=0\n",
    "train_acc2=0\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "cnn1 = EfficientNet('efficientnet-b8',)\n",
    "\n",
    "test_acc1, test_acc2=evaluate(test_loader, cnn1, cnn2)\n",
    "print('Epoch [%d/%d] Test Accuracy on the %s test images: Model1 %.4f %% Model2 %.4f %% Pure Ratio1 %.4f %% Pure Ratio2 %.4f %%' % (epoch+1, num_epoch, len(test_loader.dataset), test_acc1, test_acc2, mean_pure_ratio1, mean_pure_ratio2))\n",
    "# save results\n",
    "# with open(txtfile, \"a\") as myfile:\n",
    "#     myfile.write(str(int(epoch)) + ': '  + str(train_acc1) +' '  + str(train_acc2) +' '  + str(test_acc1) + \" \" + str(test_acc2) + ' '  + str(mean_pure_ratio1) + ' '  + str(mean_pure_ratio2) + \"\\n\")\n",
    "\n",
    "\n",
    "# training\n",
    "for epoch in range(1, num_epoch):\n",
    "    # train models\n",
    "    cnn1.train()\n",
    "    adjust_learning_rate(optimizer1, epoch)\n",
    "    cnn2.train()\n",
    "    adjust_learning_rate(optimizer2, epoch)\n",
    "    train_acc1, train_acc2, pure_ratio_1_list, pure_ratio_2_list=train(train_loader, epoch, cnn1, optimizer1, cnn2, optimizer2, criterion, rate_schedule, num_mixup_alpha, num_iter_per_epoch)\n",
    "    # evaluate models\n",
    "    test_acc1, test_acc2=evaluate(test_loader, cnn1, cnn2)\n",
    "    # save results\n",
    "    if dataset == 'cifar10n':\n",
    "        mean_pure_ratio1 = sum(pure_ratio_1_list)/len(pure_ratio_1_list)\n",
    "        mean_pure_ratio2 = sum(pure_ratio_2_list)/len(pure_ratio_2_list)\n",
    "        str_ratio = 'Pure Ratio 1 %.4f %%, Pure Ratio 2 %.4f' % (mean_pure_ratio1, mean_pure_ratio2)\n",
    "    else:\n",
    "        str_ratio = 'animal10n without pure ratio.'\n",
    "    print('Epoch [%d/%d] Test Accuracy on the %s test images: Model1 %.4f %% Model2 %.4f %%, %s' % (epoch+1, num_epoch, len(test_loader.dataset), test_acc1, test_acc2, str_ratio))\n",
    "    # with open(txtfile, \"a\") as myfile:\n",
    "    #     myfile.write(str(int(epoch)) + ': '  + str(train_acc1) +' '  + str(train_acc2) +' '  + str(test_acc1) + \" \" + str(test_acc2) + ' ' + str(mean_pure_ratio1) + ' ' + str(mean_pure_ratio2) + \"\\n\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def train_trial(_model1, _model2,\n",
    "                _optm1_selc, _optm2_selc,\n",
    "                _criterion,\n",
    "                _forget_rate=0.1, _gradual=10, _num_epoch=200, _num_mixup_alpha=0.1, _iter_per_epoch=200, _num_exponent=1):\n",
    "\n",
    "    _rate_schedule = np.ones(_num_epoch) * _forget_rate\n",
    "    _rate_schedule[:_gradual] = np.linspace(0, _forget_rate ** _num_exponent, _gradual)\n",
    "\n",
    "    print('Start trail...')\n",
    "    \n",
    "    # Define models\n",
    "    print('building model...')\n",
    "    _model1 = CNN(input_channel=num_input_channel, n_outputs=num_classes)\n",
    "    _model1.to(device)\n",
    "    _model2 = CNN(input_channel=num_input_channel, n_outputs=num_classes)\n",
    "    _model2.to(device)\n",
    "\n",
    "    if _optm1_selc == \"Adam\":\n",
    "        _optm1 = torch.optim.Adam(_model1.parameters(), lr=num_learning_rate)\n",
    "    elif _optm1_selc == \"SGD\":\n",
    "        _optm1 = torch.optim.SGD(_model1.parameters(), lr=num_learning_rate)\n",
    "\n",
    "    _optm1 = torch.optim.Adam(_model1.parameters(), lr=num_learning_rate)\n",
    "    _optm2 = torch.optim.Adam(_model2.parameters(), lr=num_learning_rate)\n",
    "\n",
    "    _criterion = torch.nn.CrossEntropyLoss(reduce=False)\n",
    "    _mean_pure_ratio1=0\n",
    "    _mean_pure_ratio2=0\n",
    "\n",
    "    _epoch=0\n",
    "    _train_acc1=0\n",
    "    _train_acc2=0\n",
    "    _test_acc1, _test_acc2 = 0,0\n",
    "\n",
    "    for _epoch in range(1, num_epoch):\n",
    "        # train models\n",
    "        _model1.train()\n",
    "        adjust_learning_rate(_optm1, _epoch)\n",
    "        _model2.train()\n",
    "        adjust_learning_rate(_optm2, _epoch)\n",
    "        _train_acc1, _train_acc2, _pure_ratio_1_list, _pure_ratio_2_list=train(train_loader, _epoch, _model1, _optm1, _model2, _optm2, _criterion, _rate_schedule, _num_mixup_alpha, _iter_per_epoch)\n",
    "        # evaluate models\n",
    "        _test_acc1, _test_acc2=evaluate(test_loader, _model1, _model2)\n",
    "        # save results\n",
    "        if dataset == 'cifar10n':\n",
    "            _mean_pure_ratio1 = sum(_pure_ratio_1_list)/len(_pure_ratio_1_list)\n",
    "            _mean_pure_ratio2 = sum(_pure_ratio_2_list)/len(_pure_ratio_2_list)\n",
    "            _str_ratio = 'Pure Ratio 1 %.4f %%, Pure Ratio 2 %.4f' % (_mean_pure_ratio1, _mean_pure_ratio2)\n",
    "        else:\n",
    "            _str_ratio = 'animal10n without pure ratio.'\n",
    "        print('Epoch [%d/%d] Test Accuracy on the %s test images: Model1 %.4f %% Model2 %.4f %%, %s' % (_epoch+1, num_epoch, len(test_loader.dataset), _test_acc1, _test_acc2, _str_ratio))\n",
    "        # with open(txtfile, \"a\") as myfile:\n",
    "        #     myfile.write(str(int(epoch)) + ': '  + str(train_acc1) +' '  + str(train_acc2) +' '  + str(test_acc1) + \" \" + str(test_acc2) + ' ' + str(mean_pure_ratio1) + ' ' + str(mean_pure_ratio2) + \"\\n\")\n",
    "\n",
    "    return max(_test_acc1, _test_acc2)\n",
    "\n",
    "def objective(trial):\n",
    "    _criterion_select = trial.suggest_categorical(\n",
    "        \"Criterion\",\n",
    "        [\"CEL\"])\n",
    "    _forget_rate_selection = trial.suggest_float(\n",
    "        \"Forget Rate\",\n",
    "        0.1, 0.3, log=True)\n",
    "    _gradual = trial.suggest_int(\n",
    "        \"Gradual\",\n",
    "        10, 50, log=True)\n",
    "    _mixup_alpha = trial.suggest_float(\n",
    "        \"Mixup Alpha\",\n",
    "        0.1, 0.4, step=0.1)\n",
    "    _optm1_select = trial.suggest_categorical(\n",
    "        \"Optimizer 1\",\n",
    "        [\"Adam\", \"SGD\"])\n",
    "    _optm2_select = trial.suggest_categorical(\n",
    "        \"Optimizer 2\",\n",
    "        [\"Adam\", \"SGD\"])\n",
    "    _model1_select = trial.suggest_categorical(  # TODO: Search models for training\n",
    "        \"Model 1\",\n",
    "        [\"CNN\", \"EfficientNet_v2_s\", \"EfficientNet_v2_m\", \"EfficientNet_b3\", \"EfficientNet_b2\", \"EfficientNet_b1\", \"EfficientNet_b0\"]\n",
    "    )\n",
    "# https://github.com/d-li14/efficientnetv2.pytorch/blob/main/effnetv2.py\n",
    "\n",
    "    def train_trial(_model1, _model2,\n",
    "                    _optm1_select, _optm2_select,\n",
    "                    _criterion_select,\n",
    "                    _learning_rate_schedule_select,\n",
    "                    _forget_rate=_forget_rate_selection, _gradual=_gradual, _num_epoch=200, _num_mixup_alpha=_mixup_alpha, _iter_per_epoch=200, _num_exponent=1):\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['efficientnet_b0', 'efficientnet_b1', 'efficientnet_b2', 'efficientnet_b3', 'efficientnet_es', 'efficientnet_lite0', 'fbnetc_100', 'mixnet_l', 'mixnet_m', 'mixnet_s', 'mixnet_xl', 'mnasnet_a1', 'mnasnet_b1', 'mobilenetv2_100', 'mobilenetv2_110d', 'mobilenetv2_120d', 'mobilenetv2_140', 'mobilenetv3_large_100', 'mobilenetv3_rw', 'spnasnet_100', 'tf_efficientnet_b0', 'tf_efficientnet_b0_ap', 'tf_efficientnet_b0_ns', 'tf_efficientnet_b1', 'tf_efficientnet_b1_ap', 'tf_efficientnet_b1_ns', 'tf_efficientnet_b2', 'tf_efficientnet_b2_ap', 'tf_efficientnet_b2_ns', 'tf_efficientnet_b3', 'tf_efficientnet_b3_ap', 'tf_efficientnet_b3_ns', 'tf_efficientnet_b4', 'tf_efficientnet_b4_ap', 'tf_efficientnet_b4_ns', 'tf_efficientnet_b5', 'tf_efficientnet_b5_ap', 'tf_efficientnet_b5_ns', 'tf_efficientnet_b6', 'tf_efficientnet_b6_ap', 'tf_efficientnet_b6_ns', 'tf_efficientnet_b7', 'tf_efficientnet_b7_ap', 'tf_efficientnet_b7_ns', 'tf_efficientnet_b8', 'tf_efficientnet_b8_ap', 'tf_efficientnet_cc_b0_4e', 'tf_efficientnet_cc_b0_8e', 'tf_efficientnet_cc_b1_8e', 'tf_efficientnet_el', 'tf_efficientnet_em', 'tf_efficientnet_es', 'tf_efficientnet_l2_ns', 'tf_efficientnet_l2_ns_475', 'tf_efficientnet_lite0', 'tf_efficientnet_lite1', 'tf_efficientnet_lite2', 'tf_efficientnet_lite3', 'tf_efficientnet_lite4', 'tf_mixnet_l', 'tf_mixnet_m', 'tf_mixnet_s', 'tf_mobilenetv3_large_075', 'tf_mobilenetv3_large_100', 'tf_mobilenetv3_large_minimal_100', 'tf_mobilenetv3_small_075', 'tf_mobilenetv3_small_100', 'tf_mobilenetv3_small_minimal_100']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Wenda/.cache\\torch\\hub\\rwightman_gen-efficientnet-pytorch_master\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.hub.list('rwightman/gen-efficientnet-pytorch'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Wenda/.cache\\torch\\hub\\rwightman_pytorch-image-models_master\n",
      "Using cache found in C:\\Users\\Wenda/.cache\\torch\\hub\\rwightman_pytorch-image-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating animal10n_cifar10_noisy_labels_task1.json...\n",
      "Start evaluating model 1\n",
      "Start evaluating model 2\n"
     ]
    }
   ],
   "source": [
    "modelA = torch.hub.load('rwightman/pytorch-image-models', 'tf_efficientnetv2_s_in21ft1k')\n",
    "modelB = torch.hub.load('rwightman/pytorch-image-models', 'tf_efficientnetv2_m_in21ft1k')\n",
    "modelA = modelA.to(device)\n",
    "modelB = modelB.to(device)\n",
    "\n",
    "_acc1, _acc2 = evaluate(test_loader, modelA, modelB)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Wenda/.cache\\torch\\hub\\rwightman_pytorch-image-models_master\n"
     ]
    },
    {
     "data": {
      "text/plain": "['adv_inception_v3',\n 'bat_resnext26ts',\n 'beit_base_patch16_224',\n 'beit_base_patch16_224_in22k',\n 'beit_base_patch16_384',\n 'beit_large_patch16_224',\n 'beit_large_patch16_224_in22k',\n 'beit_large_patch16_384',\n 'beit_large_patch16_512',\n 'botnet26t_256',\n 'botnet50ts_256',\n 'cait_m36_384',\n 'cait_m48_448',\n 'cait_s24_224',\n 'cait_s24_384',\n 'cait_s36_384',\n 'cait_xs24_384',\n 'cait_xxs24_224',\n 'cait_xxs24_384',\n 'cait_xxs36_224',\n 'cait_xxs36_384',\n 'coat_lite_mini',\n 'coat_lite_small',\n 'coat_lite_tiny',\n 'coat_mini',\n 'coat_tiny',\n 'convit_base',\n 'convit_small',\n 'convit_tiny',\n 'convmixer_1024_20_ks9_p14',\n 'convmixer_1536_20',\n 'convmixer_768_32',\n 'convnext_base',\n 'convnext_base_384_in22ft1k',\n 'convnext_base_in22ft1k',\n 'convnext_base_in22k',\n 'convnext_large',\n 'convnext_large_384_in22ft1k',\n 'convnext_large_in22ft1k',\n 'convnext_large_in22k',\n 'convnext_small',\n 'convnext_tiny',\n 'convnext_tiny_hnf',\n 'convnext_xlarge_384_in22ft1k',\n 'convnext_xlarge_in22ft1k',\n 'convnext_xlarge_in22k',\n 'crossvit_15_240',\n 'crossvit_15_dagger_240',\n 'crossvit_15_dagger_408',\n 'crossvit_18_240',\n 'crossvit_18_dagger_240',\n 'crossvit_18_dagger_408',\n 'crossvit_9_240',\n 'crossvit_9_dagger_240',\n 'crossvit_base_240',\n 'crossvit_small_240',\n 'crossvit_tiny_240',\n 'cspdarknet53',\n 'cspdarknet53_iabn',\n 'cspresnet50',\n 'cspresnet50d',\n 'cspresnet50w',\n 'cspresnext50',\n 'cspresnext50_iabn',\n 'darknet53',\n 'deit_base_distilled_patch16_224',\n 'deit_base_distilled_patch16_384',\n 'deit_base_patch16_224',\n 'deit_base_patch16_384',\n 'deit_small_distilled_patch16_224',\n 'deit_small_patch16_224',\n 'deit_tiny_distilled_patch16_224',\n 'deit_tiny_patch16_224',\n 'densenet121',\n 'densenet121d',\n 'densenet161',\n 'densenet169',\n 'densenet201',\n 'densenet264',\n 'densenet264d_iabn',\n 'densenetblur121d',\n 'dla102',\n 'dla102x',\n 'dla102x2',\n 'dla169',\n 'dla34',\n 'dla46_c',\n 'dla46x_c',\n 'dla60',\n 'dla60_res2net',\n 'dla60_res2next',\n 'dla60x',\n 'dla60x_c',\n 'dm_nfnet_f0',\n 'dm_nfnet_f1',\n 'dm_nfnet_f2',\n 'dm_nfnet_f3',\n 'dm_nfnet_f4',\n 'dm_nfnet_f5',\n 'dm_nfnet_f6',\n 'dpn107',\n 'dpn131',\n 'dpn68',\n 'dpn68b',\n 'dpn92',\n 'dpn98',\n 'eca_botnext26ts_256',\n 'eca_halonext26ts',\n 'eca_nfnet_l0',\n 'eca_nfnet_l1',\n 'eca_nfnet_l2',\n 'eca_nfnet_l3',\n 'eca_resnet33ts',\n 'eca_resnext26ts',\n 'eca_vovnet39b',\n 'ecaresnet101d',\n 'ecaresnet101d_pruned',\n 'ecaresnet200d',\n 'ecaresnet269d',\n 'ecaresnet26t',\n 'ecaresnet50d',\n 'ecaresnet50d_pruned',\n 'ecaresnet50t',\n 'ecaresnetlight',\n 'ecaresnext26t_32x4d',\n 'ecaresnext50t_32x4d',\n 'efficientnet_b0',\n 'efficientnet_b1',\n 'efficientnet_b1_pruned',\n 'efficientnet_b2',\n 'efficientnet_b2_pruned',\n 'efficientnet_b2a',\n 'efficientnet_b3',\n 'efficientnet_b3_pruned',\n 'efficientnet_b3a',\n 'efficientnet_b4',\n 'efficientnet_b5',\n 'efficientnet_b6',\n 'efficientnet_b7',\n 'efficientnet_b8',\n 'efficientnet_cc_b0_4e',\n 'efficientnet_cc_b0_8e',\n 'efficientnet_cc_b1_8e',\n 'efficientnet_el',\n 'efficientnet_el_pruned',\n 'efficientnet_em',\n 'efficientnet_es',\n 'efficientnet_es_pruned',\n 'efficientnet_l2',\n 'efficientnet_lite0',\n 'efficientnet_lite1',\n 'efficientnet_lite2',\n 'efficientnet_lite3',\n 'efficientnet_lite4',\n 'efficientnetv2_l',\n 'efficientnetv2_m',\n 'efficientnetv2_rw_m',\n 'efficientnetv2_rw_s',\n 'efficientnetv2_rw_t',\n 'efficientnetv2_s',\n 'efficientnetv2_xl',\n 'ens_adv_inception_resnet_v2',\n 'ese_vovnet19b_dw',\n 'ese_vovnet19b_slim',\n 'ese_vovnet19b_slim_dw',\n 'ese_vovnet39b',\n 'ese_vovnet39b_evos',\n 'ese_vovnet57b',\n 'ese_vovnet99b',\n 'ese_vovnet99b_iabn',\n 'fbnetc_100',\n 'fbnetv3_b',\n 'fbnetv3_d',\n 'fbnetv3_g',\n 'gc_efficientnetv2_rw_t',\n 'gcresnet33ts',\n 'gcresnet50t',\n 'gcresnext26ts',\n 'gcresnext50ts',\n 'gernet_l',\n 'gernet_m',\n 'gernet_s',\n 'ghostnet_050',\n 'ghostnet_100',\n 'ghostnet_130',\n 'gluon_inception_v3',\n 'gluon_resnet101_v1b',\n 'gluon_resnet101_v1c',\n 'gluon_resnet101_v1d',\n 'gluon_resnet101_v1s',\n 'gluon_resnet152_v1b',\n 'gluon_resnet152_v1c',\n 'gluon_resnet152_v1d',\n 'gluon_resnet152_v1s',\n 'gluon_resnet18_v1b',\n 'gluon_resnet34_v1b',\n 'gluon_resnet50_v1b',\n 'gluon_resnet50_v1c',\n 'gluon_resnet50_v1d',\n 'gluon_resnet50_v1s',\n 'gluon_resnext101_32x4d',\n 'gluon_resnext101_64x4d',\n 'gluon_resnext50_32x4d',\n 'gluon_senet154',\n 'gluon_seresnext101_32x4d',\n 'gluon_seresnext101_64x4d',\n 'gluon_seresnext50_32x4d',\n 'gluon_xception65',\n 'gmixer_12_224',\n 'gmixer_24_224',\n 'gmlp_b16_224',\n 'gmlp_s16_224',\n 'gmlp_ti16_224',\n 'halo2botnet50ts_256',\n 'halonet26t',\n 'halonet50ts',\n 'halonet_h1',\n 'haloregnetz_b',\n 'hardcorenas_a',\n 'hardcorenas_b',\n 'hardcorenas_c',\n 'hardcorenas_d',\n 'hardcorenas_e',\n 'hardcorenas_f',\n 'hrnet_w18',\n 'hrnet_w18_small',\n 'hrnet_w18_small_v2',\n 'hrnet_w30',\n 'hrnet_w32',\n 'hrnet_w40',\n 'hrnet_w44',\n 'hrnet_w48',\n 'hrnet_w64',\n 'ig_resnext101_32x16d',\n 'ig_resnext101_32x32d',\n 'ig_resnext101_32x48d',\n 'ig_resnext101_32x8d',\n 'inception_resnet_v2',\n 'inception_v3',\n 'inception_v4',\n 'jx_nest_base',\n 'jx_nest_small',\n 'jx_nest_tiny',\n 'lambda_resnet26rpt_256',\n 'lambda_resnet26t',\n 'lambda_resnet50ts',\n 'lamhalobotnet50ts_256',\n 'lcnet_035',\n 'lcnet_050',\n 'lcnet_075',\n 'lcnet_100',\n 'lcnet_150',\n 'legacy_senet154',\n 'legacy_seresnet101',\n 'legacy_seresnet152',\n 'legacy_seresnet18',\n 'legacy_seresnet34',\n 'legacy_seresnet50',\n 'legacy_seresnext101_32x4d',\n 'legacy_seresnext26_32x4d',\n 'legacy_seresnext50_32x4d',\n 'levit_128',\n 'levit_128s',\n 'levit_192',\n 'levit_256',\n 'levit_384',\n 'mixer_b16_224',\n 'mixer_b16_224_in21k',\n 'mixer_b16_224_miil',\n 'mixer_b16_224_miil_in21k',\n 'mixer_b32_224',\n 'mixer_l16_224',\n 'mixer_l16_224_in21k',\n 'mixer_l32_224',\n 'mixer_s16_224',\n 'mixer_s32_224',\n 'mixnet_l',\n 'mixnet_m',\n 'mixnet_s',\n 'mixnet_xl',\n 'mixnet_xxl',\n 'mnasnet_050',\n 'mnasnet_075',\n 'mnasnet_100',\n 'mnasnet_140',\n 'mnasnet_a1',\n 'mnasnet_b1',\n 'mnasnet_small',\n 'mobilenetv2_035',\n 'mobilenetv2_050',\n 'mobilenetv2_075',\n 'mobilenetv2_100',\n 'mobilenetv2_110d',\n 'mobilenetv2_120d',\n 'mobilenetv2_140',\n 'mobilenetv3_large_075',\n 'mobilenetv3_large_100',\n 'mobilenetv3_large_100_miil',\n 'mobilenetv3_large_100_miil_in21k',\n 'mobilenetv3_rw',\n 'mobilenetv3_small_050',\n 'mobilenetv3_small_075',\n 'mobilenetv3_small_100',\n 'nasnetalarge',\n 'nest_base',\n 'nest_small',\n 'nest_tiny',\n 'nf_ecaresnet101',\n 'nf_ecaresnet26',\n 'nf_ecaresnet50',\n 'nf_regnet_b0',\n 'nf_regnet_b1',\n 'nf_regnet_b2',\n 'nf_regnet_b3',\n 'nf_regnet_b4',\n 'nf_regnet_b5',\n 'nf_resnet101',\n 'nf_resnet26',\n 'nf_resnet50',\n 'nf_seresnet101',\n 'nf_seresnet26',\n 'nf_seresnet50',\n 'nfnet_f0',\n 'nfnet_f0s',\n 'nfnet_f1',\n 'nfnet_f1s',\n 'nfnet_f2',\n 'nfnet_f2s',\n 'nfnet_f3',\n 'nfnet_f3s',\n 'nfnet_f4',\n 'nfnet_f4s',\n 'nfnet_f5',\n 'nfnet_f5s',\n 'nfnet_f6',\n 'nfnet_f6s',\n 'nfnet_f7',\n 'nfnet_f7s',\n 'nfnet_l0',\n 'pit_b_224',\n 'pit_b_distilled_224',\n 'pit_s_224',\n 'pit_s_distilled_224',\n 'pit_ti_224',\n 'pit_ti_distilled_224',\n 'pit_xs_224',\n 'pit_xs_distilled_224',\n 'pnasnet5large',\n 'regnetx_002',\n 'regnetx_004',\n 'regnetx_006',\n 'regnetx_008',\n 'regnetx_016',\n 'regnetx_032',\n 'regnetx_040',\n 'regnetx_064',\n 'regnetx_080',\n 'regnetx_120',\n 'regnetx_160',\n 'regnetx_320',\n 'regnety_002',\n 'regnety_004',\n 'regnety_006',\n 'regnety_008',\n 'regnety_016',\n 'regnety_032',\n 'regnety_040',\n 'regnety_064',\n 'regnety_080',\n 'regnety_120',\n 'regnety_160',\n 'regnety_320',\n 'regnetz_b16',\n 'regnetz_c16',\n 'regnetz_d32',\n 'regnetz_d8',\n 'regnetz_d8_evob',\n 'regnetz_d8_evos',\n 'regnetz_e8',\n 'repvgg_a2',\n 'repvgg_b0',\n 'repvgg_b1',\n 'repvgg_b1g4',\n 'repvgg_b2',\n 'repvgg_b2g4',\n 'repvgg_b3',\n 'repvgg_b3g4',\n 'res2net101_26w_4s',\n 'res2net50_14w_8s',\n 'res2net50_26w_4s',\n 'res2net50_26w_6s',\n 'res2net50_26w_8s',\n 'res2net50_48w_2s',\n 'res2next50',\n 'resmlp_12_224',\n 'resmlp_12_224_dino',\n 'resmlp_12_distilled_224',\n 'resmlp_24_224',\n 'resmlp_24_224_dino',\n 'resmlp_24_distilled_224',\n 'resmlp_36_224',\n 'resmlp_36_distilled_224',\n 'resmlp_big_24_224',\n 'resmlp_big_24_224_in22ft1k',\n 'resmlp_big_24_distilled_224',\n 'resnest101e',\n 'resnest14d',\n 'resnest200e',\n 'resnest269e',\n 'resnest26d',\n 'resnest50d',\n 'resnest50d_1s4x24d',\n 'resnest50d_4s2x40d',\n 'resnet101',\n 'resnet101d',\n 'resnet152',\n 'resnet152d',\n 'resnet18',\n 'resnet18d',\n 'resnet200',\n 'resnet200d',\n 'resnet26',\n 'resnet26d',\n 'resnet26t',\n 'resnet32ts',\n 'resnet33ts',\n 'resnet34',\n 'resnet34d',\n 'resnet50',\n 'resnet50_gn',\n 'resnet50d',\n 'resnet50t',\n 'resnet51q',\n 'resnet61q',\n 'resnetaa101d',\n 'resnetaa50d',\n 'resnetblur101d',\n 'resnetblur18',\n 'resnetblur50',\n 'resnetblur50d',\n 'resnetrs101',\n 'resnetrs152',\n 'resnetrs200',\n 'resnetrs270',\n 'resnetrs350',\n 'resnetrs420',\n 'resnetrs50',\n 'resnetv2_101',\n 'resnetv2_101d',\n 'resnetv2_101x1_bitm',\n 'resnetv2_101x1_bitm_in21k',\n 'resnetv2_101x3_bitm',\n 'resnetv2_101x3_bitm_in21k',\n 'resnetv2_152',\n 'resnetv2_152d',\n 'resnetv2_152x2_bit_teacher',\n 'resnetv2_152x2_bit_teacher_384',\n 'resnetv2_152x2_bitm',\n 'resnetv2_152x2_bitm_in21k',\n 'resnetv2_152x4_bitm',\n 'resnetv2_152x4_bitm_in21k',\n 'resnetv2_50',\n 'resnetv2_50d',\n 'resnetv2_50d_evob',\n 'resnetv2_50d_evos',\n 'resnetv2_50d_gn',\n 'resnetv2_50t',\n 'resnetv2_50x1_bit_distilled',\n 'resnetv2_50x1_bitm',\n 'resnetv2_50x1_bitm_in21k',\n 'resnetv2_50x3_bitm',\n 'resnetv2_50x3_bitm_in21k',\n 'resnext101_32x4d',\n 'resnext101_32x8d',\n 'resnext101_64x4d',\n 'resnext26ts',\n 'resnext50_32x4d',\n 'resnext50d_32x4d',\n 'rexnet_100',\n 'rexnet_130',\n 'rexnet_150',\n 'rexnet_200',\n 'rexnetr_100',\n 'rexnetr_130',\n 'rexnetr_150',\n 'rexnetr_200',\n 'sebotnet33ts_256',\n 'sehalonet33ts',\n 'selecsls42',\n 'selecsls42b',\n 'selecsls60',\n 'selecsls60b',\n 'selecsls84',\n 'semnasnet_050',\n 'semnasnet_075',\n 'semnasnet_100',\n 'semnasnet_140',\n 'senet154',\n 'seresnet101',\n 'seresnet152',\n 'seresnet152d',\n 'seresnet18',\n 'seresnet200d',\n 'seresnet269d',\n 'seresnet33ts',\n 'seresnet34',\n 'seresnet50',\n 'seresnet50t',\n 'seresnetaa50d',\n 'seresnext101_32x4d',\n 'seresnext101_32x8d',\n 'seresnext26d_32x4d',\n 'seresnext26t_32x4d',\n 'seresnext26tn_32x4d',\n 'seresnext26ts',\n 'seresnext50_32x4d',\n 'skresnet18',\n 'skresnet34',\n 'skresnet50',\n 'skresnet50d',\n 'skresnext50_32x4d',\n 'spnasnet_100',\n 'ssl_resnet18',\n 'ssl_resnet50',\n 'ssl_resnext101_32x16d',\n 'ssl_resnext101_32x4d',\n 'ssl_resnext101_32x8d',\n 'ssl_resnext50_32x4d',\n 'swin_base_patch4_window12_384',\n 'swin_base_patch4_window12_384_in22k',\n 'swin_base_patch4_window7_224',\n 'swin_base_patch4_window7_224_in22k',\n 'swin_large_patch4_window12_384',\n 'swin_large_patch4_window12_384_in22k',\n 'swin_large_patch4_window7_224',\n 'swin_large_patch4_window7_224_in22k',\n 'swin_small_patch4_window7_224',\n 'swin_tiny_patch4_window7_224',\n 'swsl_resnet18',\n 'swsl_resnet50',\n 'swsl_resnext101_32x16d',\n 'swsl_resnext101_32x4d',\n 'swsl_resnext101_32x8d',\n 'swsl_resnext50_32x4d',\n 'tf_efficientnet_b0',\n 'tf_efficientnet_b0_ap',\n 'tf_efficientnet_b0_ns',\n 'tf_efficientnet_b1',\n 'tf_efficientnet_b1_ap',\n 'tf_efficientnet_b1_ns',\n 'tf_efficientnet_b2',\n 'tf_efficientnet_b2_ap',\n 'tf_efficientnet_b2_ns',\n 'tf_efficientnet_b3',\n 'tf_efficientnet_b3_ap',\n 'tf_efficientnet_b3_ns',\n 'tf_efficientnet_b4',\n 'tf_efficientnet_b4_ap',\n 'tf_efficientnet_b4_ns',\n 'tf_efficientnet_b5',\n 'tf_efficientnet_b5_ap',\n 'tf_efficientnet_b5_ns',\n 'tf_efficientnet_b6',\n 'tf_efficientnet_b6_ap',\n 'tf_efficientnet_b6_ns',\n 'tf_efficientnet_b7',\n 'tf_efficientnet_b7_ap',\n 'tf_efficientnet_b7_ns',\n 'tf_efficientnet_b8',\n 'tf_efficientnet_b8_ap',\n 'tf_efficientnet_cc_b0_4e',\n 'tf_efficientnet_cc_b0_8e',\n 'tf_efficientnet_cc_b1_8e',\n 'tf_efficientnet_el',\n 'tf_efficientnet_em',\n 'tf_efficientnet_es',\n 'tf_efficientnet_l2_ns',\n 'tf_efficientnet_l2_ns_475',\n 'tf_efficientnet_lite0',\n 'tf_efficientnet_lite1',\n 'tf_efficientnet_lite2',\n 'tf_efficientnet_lite3',\n 'tf_efficientnet_lite4',\n 'tf_efficientnetv2_b0',\n 'tf_efficientnetv2_b1',\n 'tf_efficientnetv2_b2',\n 'tf_efficientnetv2_b3',\n 'tf_efficientnetv2_l',\n 'tf_efficientnetv2_l_in21ft1k',\n 'tf_efficientnetv2_l_in21k',\n 'tf_efficientnetv2_m',\n 'tf_efficientnetv2_m_in21ft1k',\n 'tf_efficientnetv2_m_in21k',\n 'tf_efficientnetv2_s',\n 'tf_efficientnetv2_s_in21ft1k',\n 'tf_efficientnetv2_s_in21k',\n 'tf_efficientnetv2_xl_in21ft1k',\n 'tf_efficientnetv2_xl_in21k',\n 'tf_inception_v3',\n 'tf_mixnet_l',\n 'tf_mixnet_m',\n 'tf_mixnet_s',\n 'tf_mobilenetv3_large_075',\n 'tf_mobilenetv3_large_100',\n 'tf_mobilenetv3_large_minimal_100',\n 'tf_mobilenetv3_small_075',\n 'tf_mobilenetv3_small_100',\n 'tf_mobilenetv3_small_minimal_100',\n 'tinynet_a',\n 'tinynet_b',\n 'tinynet_c',\n 'tinynet_d',\n 'tinynet_e',\n 'tnt_b_patch16_224',\n 'tnt_s_patch16_224',\n 'tresnet_l',\n 'tresnet_l_448',\n 'tresnet_m',\n 'tresnet_m_448',\n 'tresnet_m_miil_in21k',\n 'tresnet_xl',\n 'tresnet_xl_448',\n 'tv_densenet121',\n 'tv_resnet101',\n 'tv_resnet152',\n 'tv_resnet34',\n 'tv_resnet50',\n 'tv_resnext50_32x4d',\n 'twins_pcpvt_base',\n 'twins_pcpvt_large',\n 'twins_pcpvt_small',\n 'twins_svt_base',\n 'twins_svt_large',\n 'twins_svt_small',\n 'vgg11',\n 'vgg11_bn',\n 'vgg13',\n 'vgg13_bn',\n 'vgg16',\n 'vgg16_bn',\n 'vgg19',\n 'vgg19_bn',\n 'visformer_small',\n 'visformer_tiny',\n 'vit_base2_patch32_256',\n 'vit_base_patch16_224',\n 'vit_base_patch16_224_dino',\n 'vit_base_patch16_224_in21k',\n 'vit_base_patch16_224_miil',\n 'vit_base_patch16_224_miil_in21k',\n 'vit_base_patch16_224_sam',\n 'vit_base_patch16_384',\n 'vit_base_patch32_224',\n 'vit_base_patch32_224_in21k',\n 'vit_base_patch32_224_sam',\n 'vit_base_patch32_384',\n 'vit_base_patch8_224',\n 'vit_base_patch8_224_dino',\n 'vit_base_patch8_224_in21k',\n 'vit_base_r26_s32_224',\n 'vit_base_r50_s16_224',\n 'vit_base_r50_s16_224_in21k',\n 'vit_base_r50_s16_384',\n 'vit_base_resnet26d_224',\n 'vit_base_resnet50_224_in21k',\n 'vit_base_resnet50_384',\n 'vit_base_resnet50d_224',\n 'vit_giant_patch14_224',\n 'vit_gigantic_patch14_224',\n 'vit_huge_patch14_224',\n 'vit_huge_patch14_224_in21k',\n 'vit_large_patch16_224',\n 'vit_large_patch16_224_in21k',\n 'vit_large_patch16_384',\n 'vit_large_patch32_224',\n 'vit_large_patch32_224_in21k',\n 'vit_large_patch32_384',\n 'vit_large_r50_s32_224',\n 'vit_large_r50_s32_224_in21k',\n 'vit_large_r50_s32_384',\n 'vit_small_patch16_224',\n 'vit_small_patch16_224_dino',\n 'vit_small_patch16_224_in21k',\n 'vit_small_patch16_384',\n 'vit_small_patch32_224',\n 'vit_small_patch32_224_in21k',\n 'vit_small_patch32_384',\n 'vit_small_patch8_224_dino',\n 'vit_small_r26_s32_224',\n 'vit_small_r26_s32_224_in21k',\n 'vit_small_r26_s32_384',\n 'vit_small_resnet26d_224',\n 'vit_small_resnet50d_s16_224',\n 'vit_tiny_patch16_224',\n 'vit_tiny_patch16_224_in21k',\n 'vit_tiny_patch16_384',\n 'vit_tiny_r_s16_p8_224',\n 'vit_tiny_r_s16_p8_224_in21k',\n 'vit_tiny_r_s16_p8_384',\n 'vovnet39a',\n 'vovnet57a',\n 'wide_resnet101_2',\n 'wide_resnet50_2',\n 'xception',\n 'xception41',\n 'xception65',\n 'xception71',\n 'xcit_large_24_p16_224',\n 'xcit_large_24_p16_224_dist',\n 'xcit_large_24_p16_384_dist',\n 'xcit_large_24_p8_224',\n 'xcit_large_24_p8_224_dist',\n 'xcit_large_24_p8_384_dist',\n 'xcit_medium_24_p16_224',\n 'xcit_medium_24_p16_224_dist',\n 'xcit_medium_24_p16_384_dist',\n 'xcit_medium_24_p8_224',\n 'xcit_medium_24_p8_224_dist',\n 'xcit_medium_24_p8_384_dist',\n 'xcit_nano_12_p16_224',\n 'xcit_nano_12_p16_224_dist',\n 'xcit_nano_12_p16_384_dist',\n 'xcit_nano_12_p8_224',\n 'xcit_nano_12_p8_224_dist',\n 'xcit_nano_12_p8_384_dist',\n 'xcit_small_12_p16_224',\n 'xcit_small_12_p16_224_dist',\n 'xcit_small_12_p16_384_dist',\n 'xcit_small_12_p8_224',\n 'xcit_small_12_p8_224_dist',\n 'xcit_small_12_p8_384_dist',\n 'xcit_small_24_p16_224',\n 'xcit_small_24_p16_224_dist',\n 'xcit_small_24_p16_384_dist',\n 'xcit_small_24_p8_224',\n 'xcit_small_24_p8_224_dist',\n 'xcit_small_24_p8_384_dist',\n 'xcit_tiny_12_p16_224',\n 'xcit_tiny_12_p16_224_dist',\n 'xcit_tiny_12_p16_384_dist',\n 'xcit_tiny_12_p8_224',\n 'xcit_tiny_12_p8_224_dist',\n 'xcit_tiny_12_p8_384_dist',\n 'xcit_tiny_24_p16_224',\n 'xcit_tiny_24_p16_224_dist',\n 'xcit_tiny_24_p16_384_dist',\n 'xcit_tiny_24_p8_224',\n 'xcit_tiny_24_p8_224_dist',\n 'xcit_tiny_24_p8_384_dist']"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.hub.list('rwightman/pytorch-image-models')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Wenda/.cache\\torch\\hub\\rwightman_pytorch-image-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 48, 32, 32]           1,296\n",
      "       BatchNorm2d-2           [-1, 48, 32, 32]              96\n",
      "              SiLU-3           [-1, 48, 32, 32]               0\n",
      "            Conv2d-4           [-1, 48, 32, 32]             432\n",
      "       BatchNorm2d-5           [-1, 48, 32, 32]              96\n",
      "              SiLU-6           [-1, 48, 32, 32]               0\n",
      "            Conv2d-7             [-1, 12, 1, 1]             588\n",
      "              SiLU-8             [-1, 12, 1, 1]               0\n",
      "            Conv2d-9             [-1, 48, 1, 1]             624\n",
      "          Sigmoid-10             [-1, 48, 1, 1]               0\n",
      "    SqueezeExcite-11           [-1, 48, 32, 32]               0\n",
      "           Conv2d-12           [-1, 24, 32, 32]           1,152\n",
      "      BatchNorm2d-13           [-1, 24, 32, 32]              48\n",
      "         Identity-14           [-1, 24, 32, 32]               0\n",
      "DepthwiseSeparableConv-15           [-1, 24, 32, 32]               0\n",
      "           Conv2d-16           [-1, 24, 32, 32]             216\n",
      "      BatchNorm2d-17           [-1, 24, 32, 32]              48\n",
      "             SiLU-18           [-1, 24, 32, 32]               0\n",
      "           Conv2d-19              [-1, 6, 1, 1]             150\n",
      "             SiLU-20              [-1, 6, 1, 1]               0\n",
      "           Conv2d-21             [-1, 24, 1, 1]             168\n",
      "          Sigmoid-22             [-1, 24, 1, 1]               0\n",
      "    SqueezeExcite-23           [-1, 24, 32, 32]               0\n",
      "           Conv2d-24           [-1, 24, 32, 32]             576\n",
      "      BatchNorm2d-25           [-1, 24, 32, 32]              48\n",
      "         Identity-26           [-1, 24, 32, 32]               0\n",
      "DepthwiseSeparableConv-27           [-1, 24, 32, 32]               0\n",
      "           Conv2d-28           [-1, 24, 32, 32]             216\n",
      "      BatchNorm2d-29           [-1, 24, 32, 32]              48\n",
      "             SiLU-30           [-1, 24, 32, 32]               0\n",
      "           Conv2d-31              [-1, 6, 1, 1]             150\n",
      "             SiLU-32              [-1, 6, 1, 1]               0\n",
      "           Conv2d-33             [-1, 24, 1, 1]             168\n",
      "          Sigmoid-34             [-1, 24, 1, 1]               0\n",
      "    SqueezeExcite-35           [-1, 24, 32, 32]               0\n",
      "           Conv2d-36           [-1, 24, 32, 32]             576\n",
      "      BatchNorm2d-37           [-1, 24, 32, 32]              48\n",
      "         Identity-38           [-1, 24, 32, 32]               0\n",
      "DepthwiseSeparableConv-39           [-1, 24, 32, 32]               0\n",
      "           Conv2d-40          [-1, 144, 32, 32]           3,456\n",
      "      BatchNorm2d-41          [-1, 144, 32, 32]             288\n",
      "             SiLU-42          [-1, 144, 32, 32]               0\n",
      "           Conv2d-43          [-1, 144, 16, 16]           1,296\n",
      "      BatchNorm2d-44          [-1, 144, 16, 16]             288\n",
      "             SiLU-45          [-1, 144, 16, 16]               0\n",
      "           Conv2d-46              [-1, 6, 1, 1]             870\n",
      "             SiLU-47              [-1, 6, 1, 1]               0\n",
      "           Conv2d-48            [-1, 144, 1, 1]           1,008\n",
      "          Sigmoid-49            [-1, 144, 1, 1]               0\n",
      "    SqueezeExcite-50          [-1, 144, 16, 16]               0\n",
      "           Conv2d-51           [-1, 40, 16, 16]           5,760\n",
      "      BatchNorm2d-52           [-1, 40, 16, 16]              80\n",
      " InvertedResidual-53           [-1, 40, 16, 16]               0\n",
      "           Conv2d-54          [-1, 240, 16, 16]           9,600\n",
      "      BatchNorm2d-55          [-1, 240, 16, 16]             480\n",
      "             SiLU-56          [-1, 240, 16, 16]               0\n",
      "           Conv2d-57          [-1, 240, 16, 16]           2,160\n",
      "      BatchNorm2d-58          [-1, 240, 16, 16]             480\n",
      "             SiLU-59          [-1, 240, 16, 16]               0\n",
      "           Conv2d-60             [-1, 10, 1, 1]           2,410\n",
      "             SiLU-61             [-1, 10, 1, 1]               0\n",
      "           Conv2d-62            [-1, 240, 1, 1]           2,640\n",
      "          Sigmoid-63            [-1, 240, 1, 1]               0\n",
      "    SqueezeExcite-64          [-1, 240, 16, 16]               0\n",
      "           Conv2d-65           [-1, 40, 16, 16]           9,600\n",
      "      BatchNorm2d-66           [-1, 40, 16, 16]              80\n",
      " InvertedResidual-67           [-1, 40, 16, 16]               0\n",
      "           Conv2d-68          [-1, 240, 16, 16]           9,600\n",
      "      BatchNorm2d-69          [-1, 240, 16, 16]             480\n",
      "             SiLU-70          [-1, 240, 16, 16]               0\n",
      "           Conv2d-71          [-1, 240, 16, 16]           2,160\n",
      "      BatchNorm2d-72          [-1, 240, 16, 16]             480\n",
      "             SiLU-73          [-1, 240, 16, 16]               0\n",
      "           Conv2d-74             [-1, 10, 1, 1]           2,410\n",
      "             SiLU-75             [-1, 10, 1, 1]               0\n",
      "           Conv2d-76            [-1, 240, 1, 1]           2,640\n",
      "          Sigmoid-77            [-1, 240, 1, 1]               0\n",
      "    SqueezeExcite-78          [-1, 240, 16, 16]               0\n",
      "           Conv2d-79           [-1, 40, 16, 16]           9,600\n",
      "      BatchNorm2d-80           [-1, 40, 16, 16]              80\n",
      " InvertedResidual-81           [-1, 40, 16, 16]               0\n",
      "           Conv2d-82          [-1, 240, 16, 16]           9,600\n",
      "      BatchNorm2d-83          [-1, 240, 16, 16]             480\n",
      "             SiLU-84          [-1, 240, 16, 16]               0\n",
      "           Conv2d-85          [-1, 240, 16, 16]           2,160\n",
      "      BatchNorm2d-86          [-1, 240, 16, 16]             480\n",
      "             SiLU-87          [-1, 240, 16, 16]               0\n",
      "           Conv2d-88             [-1, 10, 1, 1]           2,410\n",
      "             SiLU-89             [-1, 10, 1, 1]               0\n",
      "           Conv2d-90            [-1, 240, 1, 1]           2,640\n",
      "          Sigmoid-91            [-1, 240, 1, 1]               0\n",
      "    SqueezeExcite-92          [-1, 240, 16, 16]               0\n",
      "           Conv2d-93           [-1, 40, 16, 16]           9,600\n",
      "      BatchNorm2d-94           [-1, 40, 16, 16]              80\n",
      " InvertedResidual-95           [-1, 40, 16, 16]               0\n",
      "           Conv2d-96          [-1, 240, 16, 16]           9,600\n",
      "      BatchNorm2d-97          [-1, 240, 16, 16]             480\n",
      "             SiLU-98          [-1, 240, 16, 16]               0\n",
      "           Conv2d-99          [-1, 240, 16, 16]           2,160\n",
      "     BatchNorm2d-100          [-1, 240, 16, 16]             480\n",
      "            SiLU-101          [-1, 240, 16, 16]               0\n",
      "          Conv2d-102             [-1, 10, 1, 1]           2,410\n",
      "            SiLU-103             [-1, 10, 1, 1]               0\n",
      "          Conv2d-104            [-1, 240, 1, 1]           2,640\n",
      "         Sigmoid-105            [-1, 240, 1, 1]               0\n",
      "   SqueezeExcite-106          [-1, 240, 16, 16]               0\n",
      "          Conv2d-107           [-1, 40, 16, 16]           9,600\n",
      "     BatchNorm2d-108           [-1, 40, 16, 16]              80\n",
      "InvertedResidual-109           [-1, 40, 16, 16]               0\n",
      "          Conv2d-110          [-1, 240, 16, 16]           9,600\n",
      "     BatchNorm2d-111          [-1, 240, 16, 16]             480\n",
      "            SiLU-112          [-1, 240, 16, 16]               0\n",
      "          Conv2d-113            [-1, 240, 8, 8]           6,000\n",
      "     BatchNorm2d-114            [-1, 240, 8, 8]             480\n",
      "            SiLU-115            [-1, 240, 8, 8]               0\n",
      "          Conv2d-116             [-1, 10, 1, 1]           2,410\n",
      "            SiLU-117             [-1, 10, 1, 1]               0\n",
      "          Conv2d-118            [-1, 240, 1, 1]           2,640\n",
      "         Sigmoid-119            [-1, 240, 1, 1]               0\n",
      "   SqueezeExcite-120            [-1, 240, 8, 8]               0\n",
      "          Conv2d-121             [-1, 64, 8, 8]          15,360\n",
      "     BatchNorm2d-122             [-1, 64, 8, 8]             128\n",
      "InvertedResidual-123             [-1, 64, 8, 8]               0\n",
      "          Conv2d-124            [-1, 384, 8, 8]          24,576\n",
      "     BatchNorm2d-125            [-1, 384, 8, 8]             768\n",
      "            SiLU-126            [-1, 384, 8, 8]               0\n",
      "          Conv2d-127            [-1, 384, 8, 8]           9,600\n",
      "     BatchNorm2d-128            [-1, 384, 8, 8]             768\n",
      "            SiLU-129            [-1, 384, 8, 8]               0\n",
      "          Conv2d-130             [-1, 16, 1, 1]           6,160\n",
      "            SiLU-131             [-1, 16, 1, 1]               0\n",
      "          Conv2d-132            [-1, 384, 1, 1]           6,528\n",
      "         Sigmoid-133            [-1, 384, 1, 1]               0\n",
      "   SqueezeExcite-134            [-1, 384, 8, 8]               0\n",
      "          Conv2d-135             [-1, 64, 8, 8]          24,576\n",
      "     BatchNorm2d-136             [-1, 64, 8, 8]             128\n",
      "InvertedResidual-137             [-1, 64, 8, 8]               0\n",
      "          Conv2d-138            [-1, 384, 8, 8]          24,576\n",
      "     BatchNorm2d-139            [-1, 384, 8, 8]             768\n",
      "            SiLU-140            [-1, 384, 8, 8]               0\n",
      "          Conv2d-141            [-1, 384, 8, 8]           9,600\n",
      "     BatchNorm2d-142            [-1, 384, 8, 8]             768\n",
      "            SiLU-143            [-1, 384, 8, 8]               0\n",
      "          Conv2d-144             [-1, 16, 1, 1]           6,160\n",
      "            SiLU-145             [-1, 16, 1, 1]               0\n",
      "          Conv2d-146            [-1, 384, 1, 1]           6,528\n",
      "         Sigmoid-147            [-1, 384, 1, 1]               0\n",
      "   SqueezeExcite-148            [-1, 384, 8, 8]               0\n",
      "          Conv2d-149             [-1, 64, 8, 8]          24,576\n",
      "     BatchNorm2d-150             [-1, 64, 8, 8]             128\n",
      "InvertedResidual-151             [-1, 64, 8, 8]               0\n",
      "          Conv2d-152            [-1, 384, 8, 8]          24,576\n",
      "     BatchNorm2d-153            [-1, 384, 8, 8]             768\n",
      "            SiLU-154            [-1, 384, 8, 8]               0\n",
      "          Conv2d-155            [-1, 384, 8, 8]           9,600\n",
      "     BatchNorm2d-156            [-1, 384, 8, 8]             768\n",
      "            SiLU-157            [-1, 384, 8, 8]               0\n",
      "          Conv2d-158             [-1, 16, 1, 1]           6,160\n",
      "            SiLU-159             [-1, 16, 1, 1]               0\n",
      "          Conv2d-160            [-1, 384, 1, 1]           6,528\n",
      "         Sigmoid-161            [-1, 384, 1, 1]               0\n",
      "   SqueezeExcite-162            [-1, 384, 8, 8]               0\n",
      "          Conv2d-163             [-1, 64, 8, 8]          24,576\n",
      "     BatchNorm2d-164             [-1, 64, 8, 8]             128\n",
      "InvertedResidual-165             [-1, 64, 8, 8]               0\n",
      "          Conv2d-166            [-1, 384, 8, 8]          24,576\n",
      "     BatchNorm2d-167            [-1, 384, 8, 8]             768\n",
      "            SiLU-168            [-1, 384, 8, 8]               0\n",
      "          Conv2d-169            [-1, 384, 8, 8]           9,600\n",
      "     BatchNorm2d-170            [-1, 384, 8, 8]             768\n",
      "            SiLU-171            [-1, 384, 8, 8]               0\n",
      "          Conv2d-172             [-1, 16, 1, 1]           6,160\n",
      "            SiLU-173             [-1, 16, 1, 1]               0\n",
      "          Conv2d-174            [-1, 384, 1, 1]           6,528\n",
      "         Sigmoid-175            [-1, 384, 1, 1]               0\n",
      "   SqueezeExcite-176            [-1, 384, 8, 8]               0\n",
      "          Conv2d-177             [-1, 64, 8, 8]          24,576\n",
      "     BatchNorm2d-178             [-1, 64, 8, 8]             128\n",
      "InvertedResidual-179             [-1, 64, 8, 8]               0\n",
      "          Conv2d-180            [-1, 384, 8, 8]          24,576\n",
      "     BatchNorm2d-181            [-1, 384, 8, 8]             768\n",
      "            SiLU-182            [-1, 384, 8, 8]               0\n",
      "          Conv2d-183            [-1, 384, 4, 4]           3,456\n",
      "     BatchNorm2d-184            [-1, 384, 4, 4]             768\n",
      "            SiLU-185            [-1, 384, 4, 4]               0\n",
      "          Conv2d-186             [-1, 16, 1, 1]           6,160\n",
      "            SiLU-187             [-1, 16, 1, 1]               0\n",
      "          Conv2d-188            [-1, 384, 1, 1]           6,528\n",
      "         Sigmoid-189            [-1, 384, 1, 1]               0\n",
      "   SqueezeExcite-190            [-1, 384, 4, 4]               0\n",
      "          Conv2d-191            [-1, 128, 4, 4]          49,152\n",
      "     BatchNorm2d-192            [-1, 128, 4, 4]             256\n",
      "InvertedResidual-193            [-1, 128, 4, 4]               0\n",
      "          Conv2d-194            [-1, 768, 4, 4]          98,304\n",
      "     BatchNorm2d-195            [-1, 768, 4, 4]           1,536\n",
      "            SiLU-196            [-1, 768, 4, 4]               0\n",
      "          Conv2d-197            [-1, 768, 4, 4]           6,912\n",
      "     BatchNorm2d-198            [-1, 768, 4, 4]           1,536\n",
      "            SiLU-199            [-1, 768, 4, 4]               0\n",
      "          Conv2d-200             [-1, 32, 1, 1]          24,608\n",
      "            SiLU-201             [-1, 32, 1, 1]               0\n",
      "          Conv2d-202            [-1, 768, 1, 1]          25,344\n",
      "         Sigmoid-203            [-1, 768, 1, 1]               0\n",
      "   SqueezeExcite-204            [-1, 768, 4, 4]               0\n",
      "          Conv2d-205            [-1, 128, 4, 4]          98,304\n",
      "     BatchNorm2d-206            [-1, 128, 4, 4]             256\n",
      "InvertedResidual-207            [-1, 128, 4, 4]               0\n",
      "          Conv2d-208            [-1, 768, 4, 4]          98,304\n",
      "     BatchNorm2d-209            [-1, 768, 4, 4]           1,536\n",
      "            SiLU-210            [-1, 768, 4, 4]               0\n",
      "          Conv2d-211            [-1, 768, 4, 4]           6,912\n",
      "     BatchNorm2d-212            [-1, 768, 4, 4]           1,536\n",
      "            SiLU-213            [-1, 768, 4, 4]               0\n",
      "          Conv2d-214             [-1, 32, 1, 1]          24,608\n",
      "            SiLU-215             [-1, 32, 1, 1]               0\n",
      "          Conv2d-216            [-1, 768, 1, 1]          25,344\n",
      "         Sigmoid-217            [-1, 768, 1, 1]               0\n",
      "   SqueezeExcite-218            [-1, 768, 4, 4]               0\n",
      "          Conv2d-219            [-1, 128, 4, 4]          98,304\n",
      "     BatchNorm2d-220            [-1, 128, 4, 4]             256\n",
      "InvertedResidual-221            [-1, 128, 4, 4]               0\n",
      "          Conv2d-222            [-1, 768, 4, 4]          98,304\n",
      "     BatchNorm2d-223            [-1, 768, 4, 4]           1,536\n",
      "            SiLU-224            [-1, 768, 4, 4]               0\n",
      "          Conv2d-225            [-1, 768, 4, 4]           6,912\n",
      "     BatchNorm2d-226            [-1, 768, 4, 4]           1,536\n",
      "            SiLU-227            [-1, 768, 4, 4]               0\n",
      "          Conv2d-228             [-1, 32, 1, 1]          24,608\n",
      "            SiLU-229             [-1, 32, 1, 1]               0\n",
      "          Conv2d-230            [-1, 768, 1, 1]          25,344\n",
      "         Sigmoid-231            [-1, 768, 1, 1]               0\n",
      "   SqueezeExcite-232            [-1, 768, 4, 4]               0\n",
      "          Conv2d-233            [-1, 128, 4, 4]          98,304\n",
      "     BatchNorm2d-234            [-1, 128, 4, 4]             256\n",
      "InvertedResidual-235            [-1, 128, 4, 4]               0\n",
      "          Conv2d-236            [-1, 768, 4, 4]          98,304\n",
      "     BatchNorm2d-237            [-1, 768, 4, 4]           1,536\n",
      "            SiLU-238            [-1, 768, 4, 4]               0\n",
      "          Conv2d-239            [-1, 768, 4, 4]           6,912\n",
      "     BatchNorm2d-240            [-1, 768, 4, 4]           1,536\n",
      "            SiLU-241            [-1, 768, 4, 4]               0\n",
      "          Conv2d-242             [-1, 32, 1, 1]          24,608\n",
      "            SiLU-243             [-1, 32, 1, 1]               0\n",
      "          Conv2d-244            [-1, 768, 1, 1]          25,344\n",
      "         Sigmoid-245            [-1, 768, 1, 1]               0\n",
      "   SqueezeExcite-246            [-1, 768, 4, 4]               0\n",
      "          Conv2d-247            [-1, 128, 4, 4]          98,304\n",
      "     BatchNorm2d-248            [-1, 128, 4, 4]             256\n",
      "InvertedResidual-249            [-1, 128, 4, 4]               0\n",
      "          Conv2d-250            [-1, 768, 4, 4]          98,304\n",
      "     BatchNorm2d-251            [-1, 768, 4, 4]           1,536\n",
      "            SiLU-252            [-1, 768, 4, 4]               0\n",
      "          Conv2d-253            [-1, 768, 4, 4]           6,912\n",
      "     BatchNorm2d-254            [-1, 768, 4, 4]           1,536\n",
      "            SiLU-255            [-1, 768, 4, 4]               0\n",
      "          Conv2d-256             [-1, 32, 1, 1]          24,608\n",
      "            SiLU-257             [-1, 32, 1, 1]               0\n",
      "          Conv2d-258            [-1, 768, 1, 1]          25,344\n",
      "         Sigmoid-259            [-1, 768, 1, 1]               0\n",
      "   SqueezeExcite-260            [-1, 768, 4, 4]               0\n",
      "          Conv2d-261            [-1, 128, 4, 4]          98,304\n",
      "     BatchNorm2d-262            [-1, 128, 4, 4]             256\n",
      "InvertedResidual-263            [-1, 128, 4, 4]               0\n",
      "          Conv2d-264            [-1, 768, 4, 4]          98,304\n",
      "     BatchNorm2d-265            [-1, 768, 4, 4]           1,536\n",
      "            SiLU-266            [-1, 768, 4, 4]               0\n",
      "          Conv2d-267            [-1, 768, 4, 4]           6,912\n",
      "     BatchNorm2d-268            [-1, 768, 4, 4]           1,536\n",
      "            SiLU-269            [-1, 768, 4, 4]               0\n",
      "          Conv2d-270             [-1, 32, 1, 1]          24,608\n",
      "            SiLU-271             [-1, 32, 1, 1]               0\n",
      "          Conv2d-272            [-1, 768, 1, 1]          25,344\n",
      "         Sigmoid-273            [-1, 768, 1, 1]               0\n",
      "   SqueezeExcite-274            [-1, 768, 4, 4]               0\n",
      "          Conv2d-275            [-1, 128, 4, 4]          98,304\n",
      "     BatchNorm2d-276            [-1, 128, 4, 4]             256\n",
      "InvertedResidual-277            [-1, 128, 4, 4]               0\n",
      "          Conv2d-278            [-1, 768, 4, 4]          98,304\n",
      "     BatchNorm2d-279            [-1, 768, 4, 4]           1,536\n",
      "            SiLU-280            [-1, 768, 4, 4]               0\n",
      "          Conv2d-281            [-1, 768, 4, 4]          19,200\n",
      "     BatchNorm2d-282            [-1, 768, 4, 4]           1,536\n",
      "            SiLU-283            [-1, 768, 4, 4]               0\n",
      "          Conv2d-284             [-1, 32, 1, 1]          24,608\n",
      "            SiLU-285             [-1, 32, 1, 1]               0\n",
      "          Conv2d-286            [-1, 768, 1, 1]          25,344\n",
      "         Sigmoid-287            [-1, 768, 1, 1]               0\n",
      "   SqueezeExcite-288            [-1, 768, 4, 4]               0\n",
      "          Conv2d-289            [-1, 176, 4, 4]         135,168\n",
      "     BatchNorm2d-290            [-1, 176, 4, 4]             352\n",
      "InvertedResidual-291            [-1, 176, 4, 4]               0\n",
      "          Conv2d-292           [-1, 1056, 4, 4]         185,856\n",
      "     BatchNorm2d-293           [-1, 1056, 4, 4]           2,112\n",
      "            SiLU-294           [-1, 1056, 4, 4]               0\n",
      "          Conv2d-295           [-1, 1056, 4, 4]          26,400\n",
      "     BatchNorm2d-296           [-1, 1056, 4, 4]           2,112\n",
      "            SiLU-297           [-1, 1056, 4, 4]               0\n",
      "          Conv2d-298             [-1, 44, 1, 1]          46,508\n",
      "            SiLU-299             [-1, 44, 1, 1]               0\n",
      "          Conv2d-300           [-1, 1056, 1, 1]          47,520\n",
      "         Sigmoid-301           [-1, 1056, 1, 1]               0\n",
      "   SqueezeExcite-302           [-1, 1056, 4, 4]               0\n",
      "          Conv2d-303            [-1, 176, 4, 4]         185,856\n",
      "     BatchNorm2d-304            [-1, 176, 4, 4]             352\n",
      "InvertedResidual-305            [-1, 176, 4, 4]               0\n",
      "          Conv2d-306           [-1, 1056, 4, 4]         185,856\n",
      "     BatchNorm2d-307           [-1, 1056, 4, 4]           2,112\n",
      "            SiLU-308           [-1, 1056, 4, 4]               0\n",
      "          Conv2d-309           [-1, 1056, 4, 4]          26,400\n",
      "     BatchNorm2d-310           [-1, 1056, 4, 4]           2,112\n",
      "            SiLU-311           [-1, 1056, 4, 4]               0\n",
      "          Conv2d-312             [-1, 44, 1, 1]          46,508\n",
      "            SiLU-313             [-1, 44, 1, 1]               0\n",
      "          Conv2d-314           [-1, 1056, 1, 1]          47,520\n",
      "         Sigmoid-315           [-1, 1056, 1, 1]               0\n",
      "   SqueezeExcite-316           [-1, 1056, 4, 4]               0\n",
      "          Conv2d-317            [-1, 176, 4, 4]         185,856\n",
      "     BatchNorm2d-318            [-1, 176, 4, 4]             352\n",
      "InvertedResidual-319            [-1, 176, 4, 4]               0\n",
      "          Conv2d-320           [-1, 1056, 4, 4]         185,856\n",
      "     BatchNorm2d-321           [-1, 1056, 4, 4]           2,112\n",
      "            SiLU-322           [-1, 1056, 4, 4]               0\n",
      "          Conv2d-323           [-1, 1056, 4, 4]          26,400\n",
      "     BatchNorm2d-324           [-1, 1056, 4, 4]           2,112\n",
      "            SiLU-325           [-1, 1056, 4, 4]               0\n",
      "          Conv2d-326             [-1, 44, 1, 1]          46,508\n",
      "            SiLU-327             [-1, 44, 1, 1]               0\n",
      "          Conv2d-328           [-1, 1056, 1, 1]          47,520\n",
      "         Sigmoid-329           [-1, 1056, 1, 1]               0\n",
      "   SqueezeExcite-330           [-1, 1056, 4, 4]               0\n",
      "          Conv2d-331            [-1, 176, 4, 4]         185,856\n",
      "     BatchNorm2d-332            [-1, 176, 4, 4]             352\n",
      "InvertedResidual-333            [-1, 176, 4, 4]               0\n",
      "          Conv2d-334           [-1, 1056, 4, 4]         185,856\n",
      "     BatchNorm2d-335           [-1, 1056, 4, 4]           2,112\n",
      "            SiLU-336           [-1, 1056, 4, 4]               0\n",
      "          Conv2d-337           [-1, 1056, 4, 4]          26,400\n",
      "     BatchNorm2d-338           [-1, 1056, 4, 4]           2,112\n",
      "            SiLU-339           [-1, 1056, 4, 4]               0\n",
      "          Conv2d-340             [-1, 44, 1, 1]          46,508\n",
      "            SiLU-341             [-1, 44, 1, 1]               0\n",
      "          Conv2d-342           [-1, 1056, 1, 1]          47,520\n",
      "         Sigmoid-343           [-1, 1056, 1, 1]               0\n",
      "   SqueezeExcite-344           [-1, 1056, 4, 4]               0\n",
      "          Conv2d-345            [-1, 176, 4, 4]         185,856\n",
      "     BatchNorm2d-346            [-1, 176, 4, 4]             352\n",
      "InvertedResidual-347            [-1, 176, 4, 4]               0\n",
      "          Conv2d-348           [-1, 1056, 4, 4]         185,856\n",
      "     BatchNorm2d-349           [-1, 1056, 4, 4]           2,112\n",
      "            SiLU-350           [-1, 1056, 4, 4]               0\n",
      "          Conv2d-351           [-1, 1056, 4, 4]          26,400\n",
      "     BatchNorm2d-352           [-1, 1056, 4, 4]           2,112\n",
      "            SiLU-353           [-1, 1056, 4, 4]               0\n",
      "          Conv2d-354             [-1, 44, 1, 1]          46,508\n",
      "            SiLU-355             [-1, 44, 1, 1]               0\n",
      "          Conv2d-356           [-1, 1056, 1, 1]          47,520\n",
      "         Sigmoid-357           [-1, 1056, 1, 1]               0\n",
      "   SqueezeExcite-358           [-1, 1056, 4, 4]               0\n",
      "          Conv2d-359            [-1, 176, 4, 4]         185,856\n",
      "     BatchNorm2d-360            [-1, 176, 4, 4]             352\n",
      "InvertedResidual-361            [-1, 176, 4, 4]               0\n",
      "          Conv2d-362           [-1, 1056, 4, 4]         185,856\n",
      "     BatchNorm2d-363           [-1, 1056, 4, 4]           2,112\n",
      "            SiLU-364           [-1, 1056, 4, 4]               0\n",
      "          Conv2d-365           [-1, 1056, 4, 4]          26,400\n",
      "     BatchNorm2d-366           [-1, 1056, 4, 4]           2,112\n",
      "            SiLU-367           [-1, 1056, 4, 4]               0\n",
      "          Conv2d-368             [-1, 44, 1, 1]          46,508\n",
      "            SiLU-369             [-1, 44, 1, 1]               0\n",
      "          Conv2d-370           [-1, 1056, 1, 1]          47,520\n",
      "         Sigmoid-371           [-1, 1056, 1, 1]               0\n",
      "   SqueezeExcite-372           [-1, 1056, 4, 4]               0\n",
      "          Conv2d-373            [-1, 176, 4, 4]         185,856\n",
      "     BatchNorm2d-374            [-1, 176, 4, 4]             352\n",
      "InvertedResidual-375            [-1, 176, 4, 4]               0\n",
      "          Conv2d-376           [-1, 1056, 4, 4]         185,856\n",
      "     BatchNorm2d-377           [-1, 1056, 4, 4]           2,112\n",
      "            SiLU-378           [-1, 1056, 4, 4]               0\n",
      "          Conv2d-379           [-1, 1056, 2, 2]          26,400\n",
      "     BatchNorm2d-380           [-1, 1056, 2, 2]           2,112\n",
      "            SiLU-381           [-1, 1056, 2, 2]               0\n",
      "          Conv2d-382             [-1, 44, 1, 1]          46,508\n",
      "            SiLU-383             [-1, 44, 1, 1]               0\n",
      "          Conv2d-384           [-1, 1056, 1, 1]          47,520\n",
      "         Sigmoid-385           [-1, 1056, 1, 1]               0\n",
      "   SqueezeExcite-386           [-1, 1056, 2, 2]               0\n",
      "          Conv2d-387            [-1, 304, 2, 2]         321,024\n",
      "     BatchNorm2d-388            [-1, 304, 2, 2]             608\n",
      "InvertedResidual-389            [-1, 304, 2, 2]               0\n",
      "          Conv2d-390           [-1, 1824, 2, 2]         554,496\n",
      "     BatchNorm2d-391           [-1, 1824, 2, 2]           3,648\n",
      "            SiLU-392           [-1, 1824, 2, 2]               0\n",
      "          Conv2d-393           [-1, 1824, 2, 2]          45,600\n",
      "     BatchNorm2d-394           [-1, 1824, 2, 2]           3,648\n",
      "            SiLU-395           [-1, 1824, 2, 2]               0\n",
      "          Conv2d-396             [-1, 76, 1, 1]         138,700\n",
      "            SiLU-397             [-1, 76, 1, 1]               0\n",
      "          Conv2d-398           [-1, 1824, 1, 1]         140,448\n",
      "         Sigmoid-399           [-1, 1824, 1, 1]               0\n",
      "   SqueezeExcite-400           [-1, 1824, 2, 2]               0\n",
      "          Conv2d-401            [-1, 304, 2, 2]         554,496\n",
      "     BatchNorm2d-402            [-1, 304, 2, 2]             608\n",
      "InvertedResidual-403            [-1, 304, 2, 2]               0\n",
      "          Conv2d-404           [-1, 1824, 2, 2]         554,496\n",
      "     BatchNorm2d-405           [-1, 1824, 2, 2]           3,648\n",
      "            SiLU-406           [-1, 1824, 2, 2]               0\n",
      "          Conv2d-407           [-1, 1824, 2, 2]          45,600\n",
      "     BatchNorm2d-408           [-1, 1824, 2, 2]           3,648\n",
      "            SiLU-409           [-1, 1824, 2, 2]               0\n",
      "          Conv2d-410             [-1, 76, 1, 1]         138,700\n",
      "            SiLU-411             [-1, 76, 1, 1]               0\n",
      "          Conv2d-412           [-1, 1824, 1, 1]         140,448\n",
      "         Sigmoid-413           [-1, 1824, 1, 1]               0\n",
      "   SqueezeExcite-414           [-1, 1824, 2, 2]               0\n",
      "          Conv2d-415            [-1, 304, 2, 2]         554,496\n",
      "     BatchNorm2d-416            [-1, 304, 2, 2]             608\n",
      "InvertedResidual-417            [-1, 304, 2, 2]               0\n",
      "          Conv2d-418           [-1, 1824, 2, 2]         554,496\n",
      "     BatchNorm2d-419           [-1, 1824, 2, 2]           3,648\n",
      "            SiLU-420           [-1, 1824, 2, 2]               0\n",
      "          Conv2d-421           [-1, 1824, 2, 2]          45,600\n",
      "     BatchNorm2d-422           [-1, 1824, 2, 2]           3,648\n",
      "            SiLU-423           [-1, 1824, 2, 2]               0\n",
      "          Conv2d-424             [-1, 76, 1, 1]         138,700\n",
      "            SiLU-425             [-1, 76, 1, 1]               0\n",
      "          Conv2d-426           [-1, 1824, 1, 1]         140,448\n",
      "         Sigmoid-427           [-1, 1824, 1, 1]               0\n",
      "   SqueezeExcite-428           [-1, 1824, 2, 2]               0\n",
      "          Conv2d-429            [-1, 304, 2, 2]         554,496\n",
      "     BatchNorm2d-430            [-1, 304, 2, 2]             608\n",
      "InvertedResidual-431            [-1, 304, 2, 2]               0\n",
      "          Conv2d-432           [-1, 1824, 2, 2]         554,496\n",
      "     BatchNorm2d-433           [-1, 1824, 2, 2]           3,648\n",
      "            SiLU-434           [-1, 1824, 2, 2]               0\n",
      "          Conv2d-435           [-1, 1824, 2, 2]          45,600\n",
      "     BatchNorm2d-436           [-1, 1824, 2, 2]           3,648\n",
      "            SiLU-437           [-1, 1824, 2, 2]               0\n",
      "          Conv2d-438             [-1, 76, 1, 1]         138,700\n",
      "            SiLU-439             [-1, 76, 1, 1]               0\n",
      "          Conv2d-440           [-1, 1824, 1, 1]         140,448\n",
      "         Sigmoid-441           [-1, 1824, 1, 1]               0\n",
      "   SqueezeExcite-442           [-1, 1824, 2, 2]               0\n",
      "          Conv2d-443            [-1, 304, 2, 2]         554,496\n",
      "     BatchNorm2d-444            [-1, 304, 2, 2]             608\n",
      "InvertedResidual-445            [-1, 304, 2, 2]               0\n",
      "          Conv2d-446           [-1, 1824, 2, 2]         554,496\n",
      "     BatchNorm2d-447           [-1, 1824, 2, 2]           3,648\n",
      "            SiLU-448           [-1, 1824, 2, 2]               0\n",
      "          Conv2d-449           [-1, 1824, 2, 2]          45,600\n",
      "     BatchNorm2d-450           [-1, 1824, 2, 2]           3,648\n",
      "            SiLU-451           [-1, 1824, 2, 2]               0\n",
      "          Conv2d-452             [-1, 76, 1, 1]         138,700\n",
      "            SiLU-453             [-1, 76, 1, 1]               0\n",
      "          Conv2d-454           [-1, 1824, 1, 1]         140,448\n",
      "         Sigmoid-455           [-1, 1824, 1, 1]               0\n",
      "   SqueezeExcite-456           [-1, 1824, 2, 2]               0\n",
      "          Conv2d-457            [-1, 304, 2, 2]         554,496\n",
      "     BatchNorm2d-458            [-1, 304, 2, 2]             608\n",
      "InvertedResidual-459            [-1, 304, 2, 2]               0\n",
      "          Conv2d-460           [-1, 1824, 2, 2]         554,496\n",
      "     BatchNorm2d-461           [-1, 1824, 2, 2]           3,648\n",
      "            SiLU-462           [-1, 1824, 2, 2]               0\n",
      "          Conv2d-463           [-1, 1824, 2, 2]          45,600\n",
      "     BatchNorm2d-464           [-1, 1824, 2, 2]           3,648\n",
      "            SiLU-465           [-1, 1824, 2, 2]               0\n",
      "          Conv2d-466             [-1, 76, 1, 1]         138,700\n",
      "            SiLU-467             [-1, 76, 1, 1]               0\n",
      "          Conv2d-468           [-1, 1824, 1, 1]         140,448\n",
      "         Sigmoid-469           [-1, 1824, 1, 1]               0\n",
      "   SqueezeExcite-470           [-1, 1824, 2, 2]               0\n",
      "          Conv2d-471            [-1, 304, 2, 2]         554,496\n",
      "     BatchNorm2d-472            [-1, 304, 2, 2]             608\n",
      "InvertedResidual-473            [-1, 304, 2, 2]               0\n",
      "          Conv2d-474           [-1, 1824, 2, 2]         554,496\n",
      "     BatchNorm2d-475           [-1, 1824, 2, 2]           3,648\n",
      "            SiLU-476           [-1, 1824, 2, 2]               0\n",
      "          Conv2d-477           [-1, 1824, 2, 2]          45,600\n",
      "     BatchNorm2d-478           [-1, 1824, 2, 2]           3,648\n",
      "            SiLU-479           [-1, 1824, 2, 2]               0\n",
      "          Conv2d-480             [-1, 76, 1, 1]         138,700\n",
      "            SiLU-481             [-1, 76, 1, 1]               0\n",
      "          Conv2d-482           [-1, 1824, 1, 1]         140,448\n",
      "         Sigmoid-483           [-1, 1824, 1, 1]               0\n",
      "   SqueezeExcite-484           [-1, 1824, 2, 2]               0\n",
      "          Conv2d-485            [-1, 304, 2, 2]         554,496\n",
      "     BatchNorm2d-486            [-1, 304, 2, 2]             608\n",
      "InvertedResidual-487            [-1, 304, 2, 2]               0\n",
      "          Conv2d-488           [-1, 1824, 2, 2]         554,496\n",
      "     BatchNorm2d-489           [-1, 1824, 2, 2]           3,648\n",
      "            SiLU-490           [-1, 1824, 2, 2]               0\n",
      "          Conv2d-491           [-1, 1824, 2, 2]          45,600\n",
      "     BatchNorm2d-492           [-1, 1824, 2, 2]           3,648\n",
      "            SiLU-493           [-1, 1824, 2, 2]               0\n",
      "          Conv2d-494             [-1, 76, 1, 1]         138,700\n",
      "            SiLU-495             [-1, 76, 1, 1]               0\n",
      "          Conv2d-496           [-1, 1824, 1, 1]         140,448\n",
      "         Sigmoid-497           [-1, 1824, 1, 1]               0\n",
      "   SqueezeExcite-498           [-1, 1824, 2, 2]               0\n",
      "          Conv2d-499            [-1, 304, 2, 2]         554,496\n",
      "     BatchNorm2d-500            [-1, 304, 2, 2]             608\n",
      "InvertedResidual-501            [-1, 304, 2, 2]               0\n",
      "          Conv2d-502           [-1, 1824, 2, 2]         554,496\n",
      "     BatchNorm2d-503           [-1, 1824, 2, 2]           3,648\n",
      "            SiLU-504           [-1, 1824, 2, 2]               0\n",
      "          Conv2d-505           [-1, 1824, 2, 2]          16,416\n",
      "     BatchNorm2d-506           [-1, 1824, 2, 2]           3,648\n",
      "            SiLU-507           [-1, 1824, 2, 2]               0\n",
      "          Conv2d-508             [-1, 76, 1, 1]         138,700\n",
      "            SiLU-509             [-1, 76, 1, 1]               0\n",
      "          Conv2d-510           [-1, 1824, 1, 1]         140,448\n",
      "         Sigmoid-511           [-1, 1824, 1, 1]               0\n",
      "   SqueezeExcite-512           [-1, 1824, 2, 2]               0\n",
      "          Conv2d-513            [-1, 512, 2, 2]         933,888\n",
      "     BatchNorm2d-514            [-1, 512, 2, 2]           1,024\n",
      "InvertedResidual-515            [-1, 512, 2, 2]               0\n",
      "          Conv2d-516           [-1, 3072, 2, 2]       1,572,864\n",
      "     BatchNorm2d-517           [-1, 3072, 2, 2]           6,144\n",
      "            SiLU-518           [-1, 3072, 2, 2]               0\n",
      "          Conv2d-519           [-1, 3072, 2, 2]          27,648\n",
      "     BatchNorm2d-520           [-1, 3072, 2, 2]           6,144\n",
      "            SiLU-521           [-1, 3072, 2, 2]               0\n",
      "          Conv2d-522            [-1, 128, 1, 1]         393,344\n",
      "            SiLU-523            [-1, 128, 1, 1]               0\n",
      "          Conv2d-524           [-1, 3072, 1, 1]         396,288\n",
      "         Sigmoid-525           [-1, 3072, 1, 1]               0\n",
      "   SqueezeExcite-526           [-1, 3072, 2, 2]               0\n",
      "          Conv2d-527            [-1, 512, 2, 2]       1,572,864\n",
      "     BatchNorm2d-528            [-1, 512, 2, 2]           1,024\n",
      "InvertedResidual-529            [-1, 512, 2, 2]               0\n",
      "          Conv2d-530           [-1, 3072, 2, 2]       1,572,864\n",
      "     BatchNorm2d-531           [-1, 3072, 2, 2]           6,144\n",
      "            SiLU-532           [-1, 3072, 2, 2]               0\n",
      "          Conv2d-533           [-1, 3072, 2, 2]          27,648\n",
      "     BatchNorm2d-534           [-1, 3072, 2, 2]           6,144\n",
      "            SiLU-535           [-1, 3072, 2, 2]               0\n",
      "          Conv2d-536            [-1, 128, 1, 1]         393,344\n",
      "            SiLU-537            [-1, 128, 1, 1]               0\n",
      "          Conv2d-538           [-1, 3072, 1, 1]         396,288\n",
      "         Sigmoid-539           [-1, 3072, 1, 1]               0\n",
      "   SqueezeExcite-540           [-1, 3072, 2, 2]               0\n",
      "          Conv2d-541            [-1, 512, 2, 2]       1,572,864\n",
      "     BatchNorm2d-542            [-1, 512, 2, 2]           1,024\n",
      "InvertedResidual-543            [-1, 512, 2, 2]               0\n",
      "          Conv2d-544           [-1, 2048, 2, 2]       1,048,576\n",
      "     BatchNorm2d-545           [-1, 2048, 2, 2]           4,096\n",
      "            SiLU-546           [-1, 2048, 2, 2]               0\n",
      "AdaptiveAvgPool2d-547           [-1, 2048, 1, 1]               0\n",
      "         Flatten-548                 [-1, 2048]               0\n",
      "SelectAdaptivePool2d-549                 [-1, 2048]               0\n",
      "          Linear-550                 [-1, 1000]       2,049,000\n",
      "================================================================\n",
      "Total params: 30,389,784\n",
      "Trainable params: 30,389,784\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 50.89\n",
      "Params size (MB): 115.93\n",
      "Estimated Total Size (MB): 166.86\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.empty_cache()\n",
    "modelC = torch.hub.load('rwightman/pytorch-image-models', 'efficientnet_b5').to(device)\n",
    "\n",
    "summary(modelC, input_size=(3, 64, 64))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}